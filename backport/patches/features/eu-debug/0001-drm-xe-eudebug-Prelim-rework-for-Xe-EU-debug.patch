From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: Dominik Grzegorzek <dominik.grzegorzek@intel.com>
Date: Thu, 5 Dec 2024 00:46:18 +0530
Subject: drm/xe/eudebug: Prelim rework for Xe EU debug

Moved all xe_eudebug declarations and definitions to xe_drm_prelim.h
Removed xe_drm_eudebug.h Moved eudebug related files into prelim/ directory
Added prelim_ prefix where necessary.

V2: Prefix PRELIM using macros instead of file update.

Signed-off-by: Dominik Grzegorzek <dominik.grzegorzek@intel.com>
Signed-off-by: Kolanupaka Naveena <kolanupaka.naveena@intel.com>
(cherry picked from commit 33dfbae234c790ab724747233e2d40182e53b09c eudebug-dev-prelim)
Signed-off-by: S A Muqthyar Ahmed <syed.abdul.muqthyar.ahmed@intel.com>
Signed-off-by: Bommu Krishnaiah <krishnaiah.bommu@intel.com>
Signed-off-by: Pravalika Gurram <pravalika.gurram@intel.com>
---
 drivers/gpu/drm/xe/Kconfig                    |   2 +-
 drivers/gpu/drm/xe/Makefile                   |   6 +-
 .../drm/xe/{ => prelim}/xe_debug_metadata.c   |  44 +-
 .../drm/xe/{ => prelim}/xe_debug_metadata.h   |  20 +-
 .../xe/{ => prelim}/xe_debug_metadata_types.h |   2 +-
 drivers/gpu/drm/xe/{ => prelim}/xe_eudebug.c  | 402 +++++++++---------
 drivers/gpu/drm/xe/prelim/xe_eudebug.h        | 106 +++++
 .../drm/xe/{ => prelim}/xe_eudebug_types.h    |   1 +
 drivers/gpu/drm/xe/{ => prelim}/xe_gt_debug.c |  30 +-
 drivers/gpu/drm/xe/{ => prelim}/xe_gt_debug.h |  20 +-
 drivers/gpu/drm/xe/xe_device.c                |  18 +-
 drivers/gpu/drm/xe/xe_device.h                |  10 +-
 drivers/gpu/drm/xe/xe_device_types.h          |   6 +-
 drivers/gpu/drm/xe/xe_eudebug.h               | 106 -----
 drivers/gpu/drm/xe/xe_exec_queue.c            |  18 +-
 drivers/gpu/drm/xe/xe_gt_pagefault.c          |  10 +-
 drivers/gpu/drm/xe/xe_hw_engine.c             |   2 +-
 drivers/gpu/drm/xe/xe_sync.c                  |  10 +-
 drivers/gpu/drm/xe/xe_sync_types.h            |   2 +-
 drivers/gpu/drm/xe/xe_vm.c                    |  26 +-
 drivers/gpu/drm/xe/xe_vm_types.h              |   4 +-
 include/uapi/drm/xe_drm.h                     |  92 ----
 include/uapi/drm/xe_drm_eudebug.h             | 256 -----------
 include/uapi/drm/xe_drm_prelim.h              | 340 +++++++++++++++
 24 files changed, 763 insertions(+), 770 deletions(-)
 rename drivers/gpu/drm/xe/{ => prelim}/xe_debug_metadata.c (76%)
 rename drivers/gpu/drm/xe/{ => prelim}/xe_debug_metadata.h (70%)
 rename drivers/gpu/drm/xe/{ => prelim}/xe_debug_metadata_types.h (92%)
 rename drivers/gpu/drm/xe/{ => prelim}/xe_eudebug.c (87%)
 create mode 100644 drivers/gpu/drm/xe/prelim/xe_eudebug.h
 rename drivers/gpu/drm/xe/{ => prelim}/xe_eudebug_types.h (99%)
 rename drivers/gpu/drm/xe/{ => prelim}/xe_gt_debug.c (77%)
 rename drivers/gpu/drm/xe/{ => prelim}/xe_gt_debug.h (52%)
 delete mode 100644 drivers/gpu/drm/xe/xe_eudebug.h
 delete mode 100644 include/uapi/drm/xe_drm_eudebug.h

diff --git a/drivers/gpu/drm/xe/Kconfig b/drivers/gpu/drm/xe/Kconfig
index 4d45c2bed..e140d85b9 100644
--- a/drivers/gpu/drm/xe/Kconfig
+++ b/drivers/gpu/drm/xe/Kconfig
@@ -111,7 +111,7 @@ config DRM_XE_FORCE_PROBE
 
 	  Use "!*" to block the probe of the driver for all known devices.
 
-config DRM_XE_EUDEBUG
+config PRELIM_DRM_XE_EUDEBUG
 	bool "Enable gdb debugger support (eudebug)"
 	depends on DRM_XE
 	default y
diff --git a/drivers/gpu/drm/xe/Makefile b/drivers/gpu/drm/xe/Makefile
index 6897772f9..9fcf41173 100644
--- a/drivers/gpu/drm/xe/Makefile
+++ b/drivers/gpu/drm/xe/Makefile
@@ -49,7 +49,7 @@ xe-y += xe_bb.o \
 	xe_gt_clock.o \
 	xe_gt_freq.o \
 	xe_gt_idle.o \
-	xe_gt_debug.o \
+	prelim/xe_gt_debug.o \
 	xe_gt_mcr.o \
 	xe_gt_pagefault.o \
 	xe_gt_sysfs.o \
@@ -125,8 +125,8 @@ xe-y += xe_bb.o \
 	xe_wait_user_fence.o \
 	xe_wopcm.o
 
-xe-$(CONFIG_DRM_XE_EUDEBUG) += xe_eudebug.o \
-	xe_debug_metadata.o
+xe-$(CONFIG_PRELIM_DRM_XE_EUDEBUG) += prelim/xe_eudebug.o \
+	prelim/xe_debug_metadata.o
 
 xe-$(CONFIG_HMM_MIRROR) += xe_hmm.o
 xe-$(CONFIG_DRM_GPUSVM) += xe_svm.o
diff --git a/drivers/gpu/drm/xe/xe_debug_metadata.c b/drivers/gpu/drm/xe/prelim/xe_debug_metadata.c
similarity index 76%
rename from drivers/gpu/drm/xe/xe_debug_metadata.c
rename to drivers/gpu/drm/xe/prelim/xe_debug_metadata.c
index 172fe2b33..243232efa 100644
--- a/drivers/gpu/drm/xe/xe_debug_metadata.c
+++ b/drivers/gpu/drm/xe/prelim/xe_debug_metadata.c
@@ -9,7 +9,7 @@
 #include <uapi/drm/xe_drm.h>
 
 #include "xe_device.h"
-#include "xe_eudebug.h"
+#include "prelim/xe_eudebug.h"
 #include "xe_macros.h"
 #include "xe_vm.h"
 
@@ -77,8 +77,8 @@ int vm_bind_op_ext_attach_debug(struct xe_device *xe,
 				u32 operation, u64 extension)
 {
 	u64 __user *address = u64_to_user_ptr(extension);
-	struct drm_xe_vm_bind_op_ext_attach_debug ext;
-	struct xe_debug_metadata *mdata;
+	struct prelim_drm_xe_vm_bind_op_ext_attach_debug ext;
+	struct prelim_xe_debug_metadata *mdata;
 	struct drm_gpuva_op *__op;
 	int err;
 
@@ -94,12 +94,12 @@ int vm_bind_op_ext_attach_debug(struct xe_device *xe,
 	if (XE_IOCTL_DBG(xe, ext.flags))
 		return -EINVAL;
 
-	mdata = xe_debug_metadata_get(xef, (u32)ext.metadata_id);
+	mdata = prelim_xe_debug_metadata_get(xef, (u32)ext.metadata_id);
 	if (XE_IOCTL_DBG(xe, !mdata))
 		return -ENOENT;
 
 	/* care about metadata existence only on the time of attach */
-	xe_debug_metadata_put(mdata);
+	prelim_xe_debug_metadata_put(mdata);
 
 	if (!ops)
 		return 0;
@@ -119,22 +119,22 @@ int vm_bind_op_ext_attach_debug(struct xe_device *xe,
 	return 0;
 }
 
-static void xe_debug_metadata_release(struct kref *ref)
+static void prelim_xe_debug_metadata_release(struct kref *ref)
 {
-	struct xe_debug_metadata *mdata = container_of(ref, struct xe_debug_metadata, refcount);
+	struct prelim_xe_debug_metadata *mdata = container_of(ref, struct prelim_xe_debug_metadata, refcount);
 
 	kvfree(mdata->ptr);
 	kfree(mdata);
 }
 
-void xe_debug_metadata_put(struct xe_debug_metadata *mdata)
+void prelim_xe_debug_metadata_put(struct prelim_xe_debug_metadata *mdata)
 {
-	kref_put(&mdata->refcount, xe_debug_metadata_release);
+	kref_put(&mdata->refcount, prelim_xe_debug_metadata_release);
 }
 
-struct xe_debug_metadata *xe_debug_metadata_get(struct xe_file *xef, u32 id)
+struct prelim_xe_debug_metadata *prelim_xe_debug_metadata_get(struct xe_file *xef, u32 id)
 {
-	struct xe_debug_metadata *mdata;
+	struct prelim_xe_debug_metadata *mdata;
 
 	mutex_lock(&xef->eudebug.metadata.lock);
 	mdata = xa_load(&xef->eudebug.metadata.xa, id);
@@ -145,21 +145,21 @@ struct xe_debug_metadata *xe_debug_metadata_get(struct xe_file *xef, u32 id)
 	return mdata;
 }
 
-int xe_debug_metadata_create_ioctl(struct drm_device *dev,
+int prelim_xe_debug_metadata_create_ioctl(struct drm_device *dev,
 				   void *data,
 				   struct drm_file *file)
 {
 	struct xe_device *xe = to_xe_device(dev);
 	struct xe_file *xef = to_xe_file(file);
-	struct drm_xe_debug_metadata_create *args = data;
-	struct xe_debug_metadata *mdata;
+	struct prelim_drm_xe_debug_metadata_create *args = data;
+	struct prelim_xe_debug_metadata *mdata;
 	int err;
 	u32 id;
 
 	if (XE_IOCTL_DBG(xe, args->extensions))
 		return -EINVAL;
 
-	if (XE_IOCTL_DBG(xe, args->type >= WORK_IN_PROGRESS_DRM_XE_DEBUG_METADATA_NUM))
+	if (XE_IOCTL_DBG(xe, args->type >= PRELIM_WORK_IN_PROGRESS_DRM_XE_DEBUG_METADATA_NUM))
 		return -EINVAL;
 
 	if (XE_IOCTL_DBG(xe, !args->user_addr || !args->len))
@@ -198,23 +198,23 @@ int xe_debug_metadata_create_ioctl(struct drm_device *dev,
 
 	args->metadata_id = id;
 
-	xe_eudebug_debug_metadata_create(xef, mdata);
+	prelim_xe_eudebug_debug_metadata_create(xef, mdata);
 
 	return 0;
 
 put_mdata:
-	xe_debug_metadata_put(mdata);
+	prelim_xe_debug_metadata_put(mdata);
 	return err;
 }
 
-int xe_debug_metadata_destroy_ioctl(struct drm_device *dev,
+int prelim_xe_debug_metadata_destroy_ioctl(struct drm_device *dev,
 				    void *data,
 				    struct drm_file *file)
 {
 	struct xe_device *xe = to_xe_device(dev);
 	struct xe_file *xef = to_xe_file(file);
-	struct drm_xe_debug_metadata_destroy * const args = data;
-	struct xe_debug_metadata *mdata;
+	struct prelim_drm_xe_debug_metadata_destroy * const args = data;
+	struct prelim_xe_debug_metadata *mdata;
 
 	if (XE_IOCTL_DBG(xe, args->extensions))
 		return -EINVAL;
@@ -225,9 +225,9 @@ int xe_debug_metadata_destroy_ioctl(struct drm_device *dev,
 	if (XE_IOCTL_DBG(xe, !mdata))
 		return -ENOENT;
 
-	xe_eudebug_debug_metadata_destroy(xef, mdata);
+	prelim_xe_eudebug_debug_metadata_destroy(xef, mdata);
 
-	xe_debug_metadata_put(mdata);
+	prelim_xe_debug_metadata_put(mdata);
 
 	return 0;
 }
diff --git a/drivers/gpu/drm/xe/xe_debug_metadata.h b/drivers/gpu/drm/xe/prelim/xe_debug_metadata.h
similarity index 70%
rename from drivers/gpu/drm/xe/xe_debug_metadata.h
rename to drivers/gpu/drm/xe/prelim/xe_debug_metadata.h
index 13b763ee0..68a8c05e9 100644
--- a/drivers/gpu/drm/xe/xe_debug_metadata.h
+++ b/drivers/gpu/drm/xe/prelim/xe_debug_metadata.h
@@ -12,19 +12,19 @@ struct drm_device;
 struct drm_file;
 struct xe_file;
 
-#if IS_ENABLED(CONFIG_DRM_XE_EUDEBUG)
+#if IS_ENABLED(CONFIG_PRELIM_DRM_XE_EUDEBUG)
 
 #include "xe_debug_metadata_types.h"
 #include "xe_vm_types.h"
 
-struct xe_debug_metadata *xe_debug_metadata_get(struct xe_file *xef, u32 id);
-void xe_debug_metadata_put(struct xe_debug_metadata *mdata);
+struct prelim_xe_debug_metadata *prelim_xe_debug_metadata_get(struct xe_file *xef, u32 id);
+void prelim_xe_debug_metadata_put(struct prelim_xe_debug_metadata *mdata);
 
-int xe_debug_metadata_create_ioctl(struct drm_device *dev,
+int prelim_xe_debug_metadata_create_ioctl(struct drm_device *dev,
 				   void *data,
 				   struct drm_file *file);
 
-int xe_debug_metadata_destroy_ioctl(struct drm_device *dev,
+int prelim_xe_debug_metadata_destroy_ioctl(struct drm_device *dev,
 				    void *data,
 				    struct drm_file *file);
 
@@ -47,22 +47,22 @@ int vm_bind_op_ext_attach_debug(struct xe_device *xe,
 
 #include <linux/errno.h>
 
-struct xe_debug_metadata;
+struct prelim_xe_debug_metadata;
 struct xe_device;
 struct xe_eudebug_vma_metadata;
 struct drm_gpuva_ops;
 
-static inline struct xe_debug_metadata *xe_debug_metadata_get(struct xe_file *xef, u32 id) { return NULL; }
-static inline void xe_debug_metadata_put(struct xe_debug_metadata *mdata) { }
+static inline struct prelim_xe_debug_metadata *prelim_xe_debug_metadata_get(struct xe_file *xef, u32 id) { return NULL; }
+static inline void prelim_xe_debug_metadata_put(struct prelim_xe_debug_metadata *mdata) { }
 
-static inline int xe_debug_metadata_create_ioctl(struct drm_device *dev,
+static inline int prelim_xe_debug_metadata_create_ioctl(struct drm_device *dev,
 						 void *data,
 						 struct drm_file *file)
 {
 	return -EOPNOTSUPP;
 }
 
-static inline int xe_debug_metadata_destroy_ioctl(struct drm_device *dev,
+static inline int prelim_xe_debug_metadata_destroy_ioctl(struct drm_device *dev,
 						  void *data,
 						  struct drm_file *file)
 {
diff --git a/drivers/gpu/drm/xe/xe_debug_metadata_types.h b/drivers/gpu/drm/xe/prelim/xe_debug_metadata_types.h
similarity index 92%
rename from drivers/gpu/drm/xe/xe_debug_metadata_types.h
rename to drivers/gpu/drm/xe/prelim/xe_debug_metadata_types.h
index 624852920..7d3db6a00 100644
--- a/drivers/gpu/drm/xe/xe_debug_metadata_types.h
+++ b/drivers/gpu/drm/xe/prelim/xe_debug_metadata_types.h
@@ -8,7 +8,7 @@
 
 #include <linux/kref.h>
 
-struct xe_debug_metadata {
+struct prelim_xe_debug_metadata {
 	/** @type: type of given metadata */
 	u64 type;
 
diff --git a/drivers/gpu/drm/xe/xe_eudebug.c b/drivers/gpu/drm/xe/prelim/xe_eudebug.c
similarity index 87%
rename from drivers/gpu/drm/xe/xe_eudebug.c
rename to drivers/gpu/drm/xe/prelim/xe_eudebug.c
index 4736803de..1655c4182 100644
--- a/drivers/gpu/drm/xe/xe_eudebug.c
+++ b/drivers/gpu/drm/xe/prelim/xe_eudebug.c
@@ -23,8 +23,8 @@
 #include "xe_debug_metadata.h"
 #include "xe_device.h"
 #include "xe_debug_metadata.h"
-#include "xe_eudebug.h"
-#include "xe_eudebug_types.h"
+#include "prelim/xe_eudebug.h"
+#include "prelim/xe_eudebug_types.h"
 #include "xe_exec_queue.h"
 #include "xe_exec_queue_types.h"
 #include "xe_force_wake.h"
@@ -256,7 +256,7 @@ static void xe_eudebug_free(struct kref *ref)
 	kfree_rcu(d, rcu);
 }
 
-void xe_eudebug_put(struct xe_eudebug *d)
+void prelim_xe_eudebug_put(struct xe_eudebug *d)
 {
 	kref_put(&d->ref, xe_eudebug_free);
 }
@@ -456,7 +456,7 @@ static bool xe_eudebug_detach(struct xe_device *xe,
 	release_acks(d);
 
 	/* Our ref with the connection_link */
-	xe_eudebug_put(d);
+	prelim_xe_eudebug_put(d);
 
 	return true;
 }
@@ -485,7 +485,7 @@ static int xe_eudebug_release(struct inode *inode, struct file *file)
 	struct xe_eudebug *d = file->private_data;
 
 	xe_eudebug_disconnect(d, 0);
-	xe_eudebug_put(d);
+	prelim_xe_eudebug_put(d);
 
 	return 0;
 }
@@ -573,7 +573,7 @@ _xe_eudebug_get(struct xe_file *xef)
 		return NULL;
 
 	if (xe_eudebug_detached(d)) {
-		xe_eudebug_put(d);
+		prelim_xe_eudebug_put(d);
 		return NULL;
 	}
 
@@ -581,7 +581,7 @@ _xe_eudebug_get(struct xe_file *xef)
 }
 
 struct xe_eudebug *
-xe_eudebug_get(struct xe_file *xef)
+prelim_xe_eudebug_get(struct xe_file *xef)
 {
 	struct xe_eudebug *d;
 
@@ -590,7 +590,7 @@ xe_eudebug_get(struct xe_file *xef)
 	d = _xe_eudebug_get(xef);
 	if (d) {
 		if (!completion_done(&d->discovery)) {
-			xe_eudebug_put(d);
+			prelim_xe_eudebug_put(d);
 			d = NULL;
 		}
 	}
@@ -606,7 +606,7 @@ static int xe_eudebug_queue_event(struct xe_eudebug *d,
 
 	xe_eudebug_assert(d, event->len > sizeof(struct xe_eudebug_event));
 	xe_eudebug_assert(d, event->type);
-	xe_eudebug_assert(d, event->type != DRM_XE_EUDEBUG_EVENT_READ);
+	xe_eudebug_assert(d, event->type != PRELIM_DRM_XE_EUDEBUG_EVENT_READ);
 
 	start_ts = ktime_get();
 	last_read_detected_ts = start_ts;
@@ -919,12 +919,12 @@ static struct xe_eudebug_event *
 xe_eudebug_create_event(struct xe_eudebug *d, u16 type, u64 seqno, u16 flags,
 			u32 len)
 {
-	const u16 max_event = DRM_XE_EUDEBUG_EVENT_PAGEFAULT;
+	const u16 max_event = PRELIM_DRM_XE_EUDEBUG_EVENT_PAGEFAULT;
 	const u16 known_flags =
-		DRM_XE_EUDEBUG_EVENT_CREATE |
-		DRM_XE_EUDEBUG_EVENT_DESTROY |
-		DRM_XE_EUDEBUG_EVENT_STATE_CHANGE |
-		DRM_XE_EUDEBUG_EVENT_NEED_ACK;
+		PRELIM_DRM_XE_EUDEBUG_EVENT_CREATE |
+		PRELIM_DRM_XE_EUDEBUG_EVENT_DESTROY |
+		PRELIM_DRM_XE_EUDEBUG_EVENT_STATE_CHANGE |
+		PRELIM_DRM_XE_EUDEBUG_EVENT_NEED_ACK;
 	struct xe_eudebug_event *event;
 
 	BUILD_BUG_ON(type > max_event);
@@ -950,11 +950,11 @@ static long xe_eudebug_read_event(struct xe_eudebug *d,
 				  const bool wait)
 {
 	struct xe_device *xe = d->xe;
-	struct drm_xe_eudebug_event __user * const user_orig =
+	struct prelim_drm_xe_eudebug_event __user * const user_orig =
 		u64_to_user_ptr(arg);
-	struct drm_xe_eudebug_event user_event;
+	struct prelim_drm_xe_eudebug_event user_event;
 	struct xe_eudebug_event *event;
-	const unsigned int max_event = DRM_XE_EUDEBUG_EVENT_PAGEFAULT;
+	const unsigned int max_event = PRELIM_DRM_XE_EUDEBUG_EVENT_PAGEFAULT;
 	long ret = 0;
 
 	if (XE_IOCTL_DBG(xe, copy_from_user(&user_event, user_orig, sizeof(user_event))))
@@ -966,7 +966,7 @@ static long xe_eudebug_read_event(struct xe_eudebug *d,
 	if (XE_IOCTL_DBG(xe, user_event.type > max_event))
 		return -EINVAL;
 
-	if (XE_IOCTL_DBG(xe, user_event.type != DRM_XE_EUDEBUG_EVENT_READ))
+	if (XE_IOCTL_DBG(xe, user_event.type != PRELIM_DRM_XE_EUDEBUG_EVENT_READ))
 		return -EINVAL;
 
 	if (XE_IOCTL_DBG(xe, user_event.len < sizeof(*user_orig)))
@@ -1034,9 +1034,9 @@ xe_eudebug_ack_event_ioctl(struct xe_eudebug *d,
 			   const unsigned int cmd,
 			   const u64 arg)
 {
-	struct drm_xe_eudebug_ack_event __user * const user_ptr =
+	struct prelim_drm_xe_eudebug_ack_event __user * const user_ptr =
 		u64_to_user_ptr(arg);
-	struct drm_xe_eudebug_ack_event user_arg;
+	struct prelim_drm_xe_eudebug_ack_event user_arg;
 	struct xe_eudebug_ack *ack;
 	struct xe_device *xe = d->xe;
 
@@ -1068,8 +1068,8 @@ xe_eudebug_ack_event_ioctl(struct xe_eudebug *d,
 }
 
 static int do_eu_control(struct xe_eudebug *d,
-			 const struct drm_xe_eudebug_eu_control * const arg,
-			 struct drm_xe_eudebug_eu_control __user * const user_ptr)
+			 const struct prelim_drm_xe_eudebug_eu_control * const arg,
+			 struct prelim_drm_xe_eudebug_eu_control __user * const user_ptr)
 {
 	void __user * const bitmask_ptr = u64_to_user_ptr(arg->bitmask_ptr);
 	struct xe_device *xe = d->xe;
@@ -1115,7 +1115,7 @@ static int do_eu_control(struct xe_eudebug *d,
 		goto queue_put;
 	}
 
-	hw_attn_size = xe_gt_eu_attention_bitmap_size(q->gt);
+	hw_attn_size = prelim_xe_gt_eu_attention_bitmap_size(q->gt);
 	attn_size = arg->bitmask_size;
 
 	if (attn_size > hw_attn_size)
@@ -1160,15 +1160,15 @@ static int do_eu_control(struct xe_eudebug *d,
 	}
 
 	switch (arg->cmd) {
-	case DRM_XE_EUDEBUG_EU_CONTROL_CMD_INTERRUPT_ALL:
+	case PRELIM_DRM_XE_EUDEBUG_EU_CONTROL_CMD_INTERRUPT_ALL:
 		/* Make sure we dont promise anything but interrupting all */
 		if (!attn_size)
 			ret = d->ops->interrupt_all(d, q, lrc);
 		break;
-	case DRM_XE_EUDEBUG_EU_CONTROL_CMD_STOPPED:
+	case PRELIM_DRM_XE_EUDEBUG_EU_CONTROL_CMD_STOPPED:
 		ret = d->ops->stopped(d, q, lrc, bits, attn_size);
 		break;
-	case DRM_XE_EUDEBUG_EU_CONTROL_CMD_RESUME:
+	case PRELIM_DRM_XE_EUDEBUG_EU_CONTROL_CMD_RESUME:
 		ret = d->ops->resume(d, q, lrc, bits, attn_size);
 		break;
 	default:
@@ -1208,20 +1208,20 @@ static int do_eu_control(struct xe_eudebug *d,
 
 static long xe_eudebug_eu_control(struct xe_eudebug *d, const u64 arg)
 {
-	struct drm_xe_eudebug_eu_control __user * const user_ptr =
+	struct prelim_drm_xe_eudebug_eu_control __user * const user_ptr =
 		u64_to_user_ptr(arg);
-	struct drm_xe_eudebug_eu_control user_arg;
+	struct prelim_drm_xe_eudebug_eu_control user_arg;
 	struct xe_device *xe = d->xe;
 	struct xe_file *xef;
 	int ret;
 
-	if (XE_IOCTL_DBG(xe, !(_IOC_DIR(DRM_XE_EUDEBUG_IOCTL_EU_CONTROL) & _IOC_WRITE)))
+	if (XE_IOCTL_DBG(xe, !(_IOC_DIR(PRELIM_DRM_XE_EUDEBUG_IOCTL_EU_CONTROL) & _IOC_WRITE)))
 		return -EINVAL;
 
-	if (XE_IOCTL_DBG(xe, !(_IOC_DIR(DRM_XE_EUDEBUG_IOCTL_EU_CONTROL) & _IOC_READ)))
+	if (XE_IOCTL_DBG(xe, !(_IOC_DIR(PRELIM_DRM_XE_EUDEBUG_IOCTL_EU_CONTROL) & _IOC_READ)))
 		return -EINVAL;
 
-	if (XE_IOCTL_DBG(xe, _IOC_SIZE(DRM_XE_EUDEBUG_IOCTL_EU_CONTROL) != sizeof(user_arg)))
+	if (XE_IOCTL_DBG(xe, _IOC_SIZE(PRELIM_DRM_XE_EUDEBUG_IOCTL_EU_CONTROL) != sizeof(user_arg)))
 		return -EINVAL;
 
 	if (copy_from_user(&user_arg,
@@ -1256,10 +1256,10 @@ static long xe_eudebug_eu_control(struct xe_eudebug *d, const u64 arg)
 	return ret;
 }
 
-static struct xe_debug_metadata *find_metadata_get(struct xe_eudebug *d,
+static struct prelim_xe_debug_metadata *find_metadata_get(struct xe_eudebug *d,
 						   u32 id)
 {
-	struct xe_debug_metadata *m;
+	struct prelim_xe_debug_metadata *m;
 
 	mutex_lock(&d->res->lock);
 	m = find_resource__unlocked(d->res, XE_EUDEBUG_RES_TYPE_METADATA, id);
@@ -1274,8 +1274,8 @@ static long xe_eudebug_read_metadata(struct xe_eudebug *d,
 				     unsigned int cmd,
 				     const u64 arg)
 {
-	struct drm_xe_eudebug_read_metadata user_arg;
-	struct xe_debug_metadata *mdata;
+	struct prelim_drm_xe_eudebug_read_metadata user_arg;
+	struct prelim_xe_debug_metadata *mdata;
 	struct xe_file *xef;
 	struct xe_device *xe = d->xe;
 	long ret = 0;
@@ -1335,7 +1335,7 @@ static long xe_eudebug_read_metadata(struct xe_eudebug *d,
 		ret = -EFAULT;
 
 metadata_put:
-	xe_debug_metadata_put(mdata);
+	prelim_xe_debug_metadata_put(mdata);
 	xe_file_put(xef);
 	return ret;
 }
@@ -1349,28 +1349,28 @@ static long xe_eudebug_ioctl(struct file *file,
 	struct xe_eudebug * const d = file->private_data;
 	long ret;
 
-	if (cmd != DRM_XE_EUDEBUG_IOCTL_READ_EVENT &&
+	if (cmd != PRELIM_DRM_XE_EUDEBUG_IOCTL_READ_EVENT &&
 	    !completion_done(&d->discovery))
 		return -EBUSY;
 
 	switch (cmd) {
-	case DRM_XE_EUDEBUG_IOCTL_READ_EVENT:
+	case PRELIM_DRM_XE_EUDEBUG_IOCTL_READ_EVENT:
 		ret = xe_eudebug_read_event(d, arg,
 					    !(file->f_flags & O_NONBLOCK));
 		break;
-	case DRM_XE_EUDEBUG_IOCTL_EU_CONTROL:
+	case PRELIM_DRM_XE_EUDEBUG_IOCTL_EU_CONTROL:
 		ret = xe_eudebug_eu_control(d, arg);
 		eu_dbg(d, "ioctl cmd=EU_CONTROL ret=%ld\n", ret);
 		break;
-	case DRM_XE_EUDEBUG_IOCTL_ACK_EVENT:
+	case PRELIM_DRM_XE_EUDEBUG_IOCTL_ACK_EVENT:
 		ret = xe_eudebug_ack_event_ioctl(d, cmd, arg);
 		eu_dbg(d, "ioctl cmd=EVENT_ACK ret=%ld\n", ret);
 		break;
-	case DRM_XE_EUDEBUG_IOCTL_VM_OPEN:
+	case PRELIM_DRM_XE_EUDEBUG_IOCTL_VM_OPEN:
 		ret = xe_eudebug_vm_open_ioctl(d, arg);
 		eu_dbg(d, "ioctl cmd=VM_OPEN ret=%ld\n", ret);
 		break;
-	case DRM_XE_EUDEBUG_IOCTL_READ_METADATA:
+	case PRELIM_DRM_XE_EUDEBUG_IOCTL_READ_METADATA:
 		ret = xe_eudebug_read_metadata(d, cmd, arg);
 		eu_dbg(d, "ioctl cmd=READ_METADATA ret=%ld\n", ret);
 		break;
@@ -1631,7 +1631,7 @@ static int send_attention_event(struct xe_eudebug *d, struct xe_exec_queue *q, i
 	struct xe_eudebug_event_eu_attention *ea;
 	struct xe_eudebug_event *event;
 	int h_c, h_queue, h_lrc;
-	u32 size = xe_gt_eu_attention_bitmap_size(q->gt);
+	u32 size = prelim_xe_gt_eu_attention_bitmap_size(q->gt);
 	u32 sz = struct_size(ea, bitmask, size);
 	int ret;
 
@@ -1651,21 +1651,21 @@ static int send_attention_event(struct xe_eudebug *d, struct xe_exec_queue *q, i
 	if (h_lrc < 0)
 		return h_lrc;
 
-	event = xe_eudebug_create_event(d, DRM_XE_EUDEBUG_EVENT_EU_ATTENTION, 0,
-					DRM_XE_EUDEBUG_EVENT_STATE_CHANGE, sz);
+	event = xe_eudebug_create_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_EU_ATTENTION, 0,
+					PRELIM_DRM_XE_EUDEBUG_EVENT_STATE_CHANGE, sz);
 
 	if (!event)
 		return -ENOSPC;
 
 	ea = cast_event(ea, event);
-	write_member(struct drm_xe_eudebug_event_eu_attention, ea, client_handle, (u64)h_c);
-	write_member(struct drm_xe_eudebug_event_eu_attention, ea, exec_queue_handle, (u64)h_queue);
-	write_member(struct drm_xe_eudebug_event_eu_attention, ea, lrc_handle, (u64)h_lrc);
-	write_member(struct drm_xe_eudebug_event_eu_attention, ea, bitmask_size, size);
+	write_member(struct prelim_drm_xe_eudebug_event_eu_attention, ea, client_handle, (u64)h_c);
+	write_member(struct prelim_drm_xe_eudebug_event_eu_attention, ea, exec_queue_handle, (u64)h_queue);
+	write_member(struct prelim_drm_xe_eudebug_event_eu_attention, ea, lrc_handle, (u64)h_lrc);
+	write_member(struct prelim_drm_xe_eudebug_event_eu_attention, ea, bitmask_size, size);
 
 	mutex_lock(&d->eu_lock);
 	event->seqno = atomic_long_inc_return(&d->events.seqno);
-	ret = xe_gt_eu_attention_bitmap(q->gt, &ea->bitmask[0], ea->bitmask_size);
+	ret = prelim_xe_gt_eu_attention_bitmap(q->gt, &ea->bitmask[0], ea->bitmask_size);
 	mutex_unlock(&d->eu_lock);
 
 	if (ret)
@@ -1709,7 +1709,7 @@ static int xe_send_gt_attention(struct xe_gt *gt)
 		xe_eudebug_disconnect(d, ret);
 
 err_eudebug_put:
-	xe_eudebug_put(d);
+	prelim_xe_eudebug_put(d);
 err_exec_queue_put:
 	xe_exec_queue_put(q);
 
@@ -1720,7 +1720,7 @@ static int xe_eudebug_handle_gt_attention(struct xe_gt *gt)
 {
 	int ret;
 
-	ret = xe_gt_eu_threads_needing_attention(gt);
+	ret = prelim_xe_gt_eu_threads_needing_attention(gt);
 	if (ret <= 0)
 		return ret;
 
@@ -1738,7 +1738,7 @@ static int send_pagefault_event(struct xe_eudebug *d, struct xe_eudebug_pagefaul
 	struct xe_eudebug_event_pagefault *ep;
 	struct xe_eudebug_event *event;
 	int h_c, h_queue, h_lrc;
-	u32 size = xe_gt_eu_attention_bitmap_size(pf->q->gt) * 3;
+	u32 size = prelim_xe_gt_eu_attention_bitmap_size(pf->q->gt) * 3;
 	u32 sz = struct_size(ep, bitmask, size);
 
 	XE_WARN_ON(pf->lrc_idx < 0 || pf->lrc_idx >= pf->q->width);
@@ -1757,8 +1757,8 @@ static int send_pagefault_event(struct xe_eudebug *d, struct xe_eudebug_pagefaul
 	if (h_lrc < 0)
 		return h_lrc;
 
-	event = xe_eudebug_create_event(d, DRM_XE_EUDEBUG_EVENT_PAGEFAULT, 0,
-					DRM_XE_EUDEBUG_EVENT_STATE_CHANGE, sz);
+	event = xe_eudebug_create_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_PAGEFAULT, 0,
+					PRELIM_DRM_XE_EUDEBUG_EVENT_STATE_CHANGE, sz);
 
 	if (!event)
 		return -ENOSPC;
@@ -1813,8 +1813,8 @@ static int send_pagefault(struct xe_gt *gt, struct xe_eudebug_pagefault *pf,
 	}
 
 	if (pf->deferred_resolved) {
-		xe_gt_eu_attentions_read(gt, &pf->attentions.resolved,
-					 XE_GT_ATTENTION_TIMEOUT_MS);
+		prelim_xe_gt_eu_attentions_read(gt, &pf->attentions.resolved,
+					 PRELIM_XE_GT_ATTENTION_TIMEOUT_MS);
 
 		if (!xe_eu_attentions_xor_count(&pf->attentions.after,
 						&pf->attentions.resolved) &&
@@ -1830,7 +1830,7 @@ static int send_pagefault(struct xe_gt *gt, struct xe_eudebug_pagefault *pf,
 		xe_eudebug_disconnect(d, ret);
 
 out_eudebug_put:
-	xe_eudebug_put(d);
+	prelim_xe_eudebug_put(d);
 out_exec_queue_put:
 	xe_exec_queue_put(q);
 
@@ -1871,7 +1871,7 @@ static int handle_gt_queued_pagefault(struct xe_gt *gt)
 	struct xe_eudebug *d;
 	int ret, lrc_idx;
 
-	ret = xe_gt_eu_threads_needing_attention(gt);
+	ret = prelim_xe_gt_eu_threads_needing_attention(gt);
 	if (ret <= 0)
 		return ret;
 
@@ -1902,7 +1902,7 @@ static int handle_gt_queued_pagefault(struct xe_gt *gt)
 	ret = send_queued_pagefault(d, true);
 
 out_eudebug_put:
-	xe_eudebug_put(d);
+	prelim_xe_eudebug_put(d);
 out_exec_queue_put:
 	xe_exec_queue_put(q);
 
@@ -2062,14 +2062,14 @@ static int check_attn_mcr(struct xe_gt *gt, void *data,
 	struct xe_eudebug *d = iter->debugger;
 	unsigned int row;
 
-	for (row = 0; row < TD_EU_ATTENTION_MAX_ROWS; row++) {
+	for (row = 0; row < PRELIM_TD_EU_ATTENTION_MAX_ROWS; row++) {
 		u32 val, cur = 0;
 
 		if (iter->i >= iter->size)
 			return 0;
 
 		if (XE_WARN_ON((iter->i + sizeof(val)) >
-				(xe_gt_eu_attention_bitmap_size(gt))))
+				(prelim_xe_gt_eu_attention_bitmap_size(gt))))
 			return -EIO;
 
 		memcpy(&val, &iter->bits[iter->i], sizeof(val));
@@ -2095,14 +2095,14 @@ static int clear_attn_mcr(struct xe_gt *gt, void *data,
 	struct xe_eudebug *d = iter->debugger;
 	unsigned int row;
 
-	for (row = 0; row < TD_EU_ATTENTION_MAX_ROWS; row++) {
+	for (row = 0; row < PRELIM_TD_EU_ATTENTION_MAX_ROWS; row++) {
 		u32 val;
 
 		if (iter->i >= iter->size)
 			return 0;
 
 		if (XE_WARN_ON((iter->i + sizeof(val)) >
-				(xe_gt_eu_attention_bitmap_size(gt))))
+				(prelim_xe_gt_eu_attention_bitmap_size(gt))))
 			return -EIO;
 
 		memcpy(&val, &iter->bits[iter->i], sizeof(val));
@@ -2157,14 +2157,14 @@ static int xe_eu_control_resume(struct xe_eudebug *d,
 	 * in order to avoid the EOT hang on PVC.
 	 */
 	if (GRAPHICS_VERx100(d->xe) == 1260) {
-		ret = xe_gt_foreach_dss_group_instance(q->gt, check_attn_mcr, &iter);
+		ret = prelim_xe_gt_foreach_dss_group_instance(q->gt, check_attn_mcr, &iter);
 		if (ret)
 			return ret;
 
 		iter.i = 0;
 	}
 
-	xe_gt_foreach_dss_group_instance(q->gt, clear_attn_mcr, &iter);
+	prelim_xe_gt_foreach_dss_group_instance(q->gt, clear_attn_mcr, &iter);
 	return 0;
 }
 
@@ -2198,7 +2198,7 @@ static int xe_eu_control_stopped(struct xe_eudebug *d,
 
 	xe_exec_queue_put(active);
 
-	return xe_gt_eu_attention_bitmap(q->gt, bits, bitmask_size);
+	return prelim_xe_gt_eu_attention_bitmap(q->gt, bits, bitmask_size);
 }
 
 static struct xe_eudebug_eu_control_ops eu_control = {
@@ -2211,7 +2211,7 @@ static void discovery_work_fn(struct work_struct *work);
 
 static int
 xe_eudebug_connect(struct xe_device *xe,
-		   struct drm_xe_eudebug_connect *param)
+		   struct prelim_drm_xe_eudebug_connect *param)
 {
 	const u64 known_open_flags = 0;
 	unsigned long f_flags = 0;
@@ -2227,10 +2227,10 @@ xe_eudebug_connect(struct xe_device *xe,
 	if (param->flags & ~known_open_flags)
 		return -EINVAL;
 
-	if (param->version && param->version != DRM_XE_EUDEBUG_VERSION)
+	if (param->version && param->version != PRELIM_DRM_XE_EUDEBUG_VERSION)
 		return -EINVAL;
 
-	param->version = DRM_XE_EUDEBUG_VERSION;
+	param->version = PRELIM_DRM_XE_EUDEBUG_VERSION;
 
 	d = kzalloc(sizeof(*d), GFP_KERNEL);
 	if (!d)
@@ -2287,12 +2287,12 @@ xe_eudebug_connect(struct xe_device *xe,
 	return err;
 }
 
-int xe_eudebug_connect_ioctl(struct drm_device *dev,
+int prelim_xe_eudebug_connect_ioctl(struct drm_device *dev,
 			     void *data,
 			     struct drm_file *file)
 {
 	struct xe_device *xe = to_xe_device(dev);
-	struct drm_xe_eudebug_connect * const param = data;
+	struct prelim_drm_xe_eudebug_connect * const param = data;
 
 	lockdep_assert_held(&xe->eudebug.discovery_lock);
 
@@ -2396,14 +2396,14 @@ static int xe_eudebug_enable(struct xe_device *xe, bool enable)
 	return 0;
 }
 
-static ssize_t enable_eudebug_show(struct device *dev, struct device_attribute *attr, char *buf)
+static ssize_t prelim_enable_eudebug_show(struct device *dev, struct device_attribute *attr, char *buf)
 {
 	struct xe_device *xe = pdev_to_xe_device(to_pci_dev(dev));
 
 	return sysfs_emit(buf, "%u\n", xe->eudebug.enable);
 }
 
-static ssize_t enable_eudebug_store(struct device *dev, struct device_attribute *attr,
+static ssize_t prelim_enable_eudebug_store(struct device *dev, struct device_attribute *attr,
 				    const char *buf, size_t count)
 {
 	struct xe_device *xe = pdev_to_xe_device(to_pci_dev(dev));
@@ -2421,16 +2421,16 @@ static ssize_t enable_eudebug_store(struct device *dev, struct device_attribute
 	return count;
 }
 
-static DEVICE_ATTR_RW(enable_eudebug);
+static DEVICE_ATTR_RW(prelim_enable_eudebug);
 
 static void xe_eudebug_sysfs_fini(void *arg)
 {
 	struct xe_device *xe = arg;
 
-	sysfs_remove_file(&xe->drm.dev->kobj, &dev_attr_enable_eudebug.attr);
+	sysfs_remove_file(&xe->drm.dev->kobj, &dev_attr_prelim_enable_eudebug.attr);
 }
 
-void xe_eudebug_init(struct xe_device *xe)
+void prelim_xe_eudebug_init(struct xe_device *xe)
 {
 	struct device *dev = xe->drm.dev;
 	int ret;
@@ -2449,7 +2449,7 @@ void xe_eudebug_init(struct xe_device *xe)
 	if (!xe->eudebug.available)
 		return;
 
-	ret = sysfs_create_file(&xe->drm.dev->kobj, &dev_attr_enable_eudebug.attr);
+	ret = sysfs_create_file(&xe->drm.dev->kobj, &dev_attr_prelim_enable_eudebug.attr);
 	if (ret)
 		drm_warn(&xe->drm, "eudebug sysfs init failed: %d, debugger unavailable\n", ret);
 	else
@@ -2458,7 +2458,7 @@ void xe_eudebug_init(struct xe_device *xe)
 	xe->eudebug.available = ret == 0;
 }
 
-void xe_eudebug_fini(struct xe_device *xe)
+void prelim_xe_eudebug_fini(struct xe_device *xe)
 {
 	attention_scan_cancel(xe);
 	xe_assert(xe, list_empty_careful(&xe->eudebug.list));
@@ -2479,14 +2479,14 @@ static int send_open_event(struct xe_eudebug *d, u32 flags, const u64 handle,
 	if (XE_WARN_ON((long)handle >= INT_MAX))
 		return -EINVAL;
 
-	event = xe_eudebug_create_event(d, DRM_XE_EUDEBUG_EVENT_OPEN, seqno,
+	event = xe_eudebug_create_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_OPEN, seqno,
 					flags, sizeof(*eo));
 	if (!event)
 		return -ENOMEM;
 
 	eo = cast_event(eo, event);
 
-	write_member(struct drm_xe_eudebug_event_client, eo,
+	write_member(struct prelim_drm_xe_eudebug_event_client, eo,
 		     client_handle, handle);
 
 	return xe_eudebug_queue_event(d, event);
@@ -2499,7 +2499,7 @@ static int client_create_event(struct xe_eudebug *d, struct xe_file *xef)
 
 	ret = xe_eudebug_add_handle(d, XE_EUDEBUG_RES_TYPE_CLIENT, xef, &seqno);
 	if (ret > 0)
-		ret = send_open_event(d, DRM_XE_EUDEBUG_EVENT_CREATE,
+		ret = send_open_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_CREATE,
 				      ret, seqno);
 
 	return ret;
@@ -2513,7 +2513,7 @@ static int client_destroy_event(struct xe_eudebug *d, struct xe_file *xef)
 	ret = xe_eudebug_remove_handle(d, XE_EUDEBUG_RES_TYPE_CLIENT,
 				       xef, &seqno);
 	if (ret > 0)
-		ret = send_open_event(d, DRM_XE_EUDEBUG_EVENT_DESTROY,
+		ret = send_open_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_DESTROY,
 				      ret, seqno);
 
 	return ret;
@@ -2522,10 +2522,10 @@ static int client_destroy_event(struct xe_eudebug *d, struct xe_file *xef)
 #define xe_eudebug_event_put(_d, _err) ({ \
 	if ((_err)) \
 		xe_eudebug_disconnect((_d), (_err)); \
-	xe_eudebug_put((_d)); \
+	prelim_xe_eudebug_put((_d)); \
 	})
 
-void xe_eudebug_file_open(struct xe_file *xef)
+void prelim_xe_eudebug_file_open(struct xe_file *xef)
 {
 	struct xe_eudebug *d;
 
@@ -2539,27 +2539,27 @@ void xe_eudebug_file_open(struct xe_file *xef)
 	list_add_tail(&xef->eudebug.client_link, &xef->xe->clients.list);
 	spin_unlock(&xef->xe->clients.lock);
 
-	d = xe_eudebug_get(xef);
+	d = prelim_xe_eudebug_get(xef);
 	if (d)
 		xe_eudebug_event_put(d, client_create_event(d, xef));
 
 	up_read(&xef->xe->eudebug.discovery_lock);
 }
 
-void xe_eudebug_file_close(struct xe_file *xef)
+void prelim_xe_eudebug_file_close(struct xe_file *xef)
 {
 	struct xe_eudebug *d;
 	unsigned long idx;
-	struct xe_debug_metadata *mdata;
+	struct prelim_xe_debug_metadata *mdata;
 
 	down_read(&xef->xe->eudebug.discovery_lock);
-	d = xe_eudebug_get(xef);
+	d = prelim_xe_eudebug_get(xef);
 	if (d)
 		xe_eudebug_event_put(d, client_destroy_event(d, xef));
 
 	mutex_lock(&xef->eudebug.metadata.lock);
 	xa_for_each(&xef->eudebug.metadata.xa, idx, mdata)
-		xe_debug_metadata_put(mdata);
+		prelim_xe_debug_metadata_put(mdata);
 	mutex_unlock(&xef->eudebug.metadata.lock);
 
 	xa_destroy(&xef->eudebug.metadata.xa);
@@ -2580,15 +2580,15 @@ static int send_vm_event(struct xe_eudebug *d, u32 flags,
 	struct xe_eudebug_event *event;
 	struct xe_eudebug_event_vm *e;
 
-	event = xe_eudebug_create_event(d, DRM_XE_EUDEBUG_EVENT_VM,
+	event = xe_eudebug_create_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_VM,
 					seqno, flags, sizeof(*e));
 	if (!event)
 		return -ENOMEM;
 
 	e = cast_event(e, event);
 
-	write_member(struct drm_xe_eudebug_event_vm, e, client_handle, client_handle);
-	write_member(struct drm_xe_eudebug_event_vm, e, vm_handle, vm_handle);
+	write_member(struct prelim_drm_xe_eudebug_event_vm, e, client_handle, client_handle);
+	write_member(struct prelim_drm_xe_eudebug_event_vm, e, vm_handle, vm_handle);
 
 	return xe_eudebug_queue_event(d, event);
 }
@@ -2613,7 +2613,7 @@ static int vm_create_event(struct xe_eudebug *d,
 	if (h_vm <= 0)
 		return h_vm;
 
-	ret = send_vm_event(d, DRM_XE_EUDEBUG_EVENT_CREATE, h_c, h_vm, seqno);
+	ret = send_vm_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_CREATE, h_c, h_vm, seqno);
 
 	return ret;
 }
@@ -2640,31 +2640,31 @@ static int vm_destroy_event(struct xe_eudebug *d,
 	if (h_vm <= 0)
 		return h_vm;
 
-	return send_vm_event(d, DRM_XE_EUDEBUG_EVENT_DESTROY, h_c, h_vm, seqno);
+	return send_vm_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_DESTROY, h_c, h_vm, seqno);
 }
 
-void xe_eudebug_vm_create(struct xe_file *xef, struct xe_vm *vm)
+void prelim_xe_eudebug_vm_create(struct xe_file *xef, struct xe_vm *vm)
 {
 	struct xe_eudebug *d;
 
 	if (!xe_vm_in_lr_mode(vm))
 		return;
 
-	d = xe_eudebug_get(xef);
+	d = prelim_xe_eudebug_get(xef);
 	if (!d)
 		return;
 
 	xe_eudebug_event_put(d, vm_create_event(d, xef, vm));
 }
 
-void xe_eudebug_vm_destroy(struct xe_file *xef, struct xe_vm *vm)
+void prelim_xe_eudebug_vm_destroy(struct xe_file *xef, struct xe_vm *vm)
 {
 	struct xe_eudebug *d;
 
 	if (!xe_vm_in_lr_mode(vm))
 		return;
 
-	d = xe_eudebug_get(xef);
+	d = prelim_xe_eudebug_get(xef);
 	if (!d)
 		return;
 
@@ -2698,19 +2698,19 @@ static int send_exec_queue_event(struct xe_eudebug *d, u32 flags,
 	if (!exec_queue_class_is_tracked(class))
 		return -EINVAL;
 
-	event = xe_eudebug_create_event(d, DRM_XE_EUDEBUG_EVENT_EXEC_QUEUE,
+	event = xe_eudebug_create_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_EXEC_QUEUE,
 					seqno, flags, sz);
 	if (!event)
 		return -ENOMEM;
 
 	e = cast_event(e, event);
 
-	write_member(struct drm_xe_eudebug_event_exec_queue, e, client_handle, client_handle);
-	write_member(struct drm_xe_eudebug_event_exec_queue, e, vm_handle, vm_handle);
-	write_member(struct drm_xe_eudebug_event_exec_queue, e, exec_queue_handle,
+	write_member(struct prelim_drm_xe_eudebug_event_exec_queue, e, client_handle, client_handle);
+	write_member(struct prelim_drm_xe_eudebug_event_exec_queue, e, vm_handle, vm_handle);
+	write_member(struct prelim_drm_xe_eudebug_event_exec_queue, e, exec_queue_handle,
 		     exec_queue_handle);
-	write_member(struct drm_xe_eudebug_event_exec_queue, e, engine_class, xe_engine_class);
-	write_member(struct drm_xe_eudebug_event_exec_queue, e, width, width);
+	write_member(struct prelim_drm_xe_eudebug_event_exec_queue, e, engine_class, xe_engine_class);
+	write_member(struct prelim_drm_xe_eudebug_event_exec_queue, e, width, width);
 
 	memcpy(e->lrc_handle, lrc_handles, width);
 
@@ -2728,20 +2728,20 @@ static int send_exec_queue_placements_event(struct xe_eudebug *d,
 	struct xe_eudebug_event *event;
 
 	event = xe_eudebug_create_event(d,
-					DRM_XE_EUDEBUG_EVENT_EXEC_QUEUE_PLACEMENTS,
-					seqno, DRM_XE_EUDEBUG_EVENT_CREATE, sz);
+					PRELIM_DRM_XE_EUDEBUG_EVENT_EXEC_QUEUE_PLACEMENTS,
+					seqno, PRELIM_DRM_XE_EUDEBUG_EVENT_CREATE, sz);
 	if (!event)
 		return -ENOMEM;
 
 	e = cast_event(e, event);
 
-	write_member(struct drm_xe_eudebug_event_exec_queue_placements, e, client_handle,
+	write_member(struct prelim_drm_xe_eudebug_event_exec_queue_placements, e, client_handle,
 		     client_handle);
-	write_member(struct drm_xe_eudebug_event_exec_queue_placements, e, vm_handle, vm_handle);
-	write_member(struct drm_xe_eudebug_event_exec_queue_placements, e, exec_queue_handle,
+	write_member(struct prelim_drm_xe_eudebug_event_exec_queue_placements, e, vm_handle, vm_handle);
+	write_member(struct prelim_drm_xe_eudebug_event_exec_queue_placements, e, exec_queue_handle,
 		     exec_queue_handle);
-	write_member(struct drm_xe_eudebug_event_exec_queue_placements, e, lrc_handle, lrc_handle);
-	write_member(struct drm_xe_eudebug_event_exec_queue_placements, e, num_placements,
+	write_member(struct prelim_drm_xe_eudebug_event_exec_queue_placements, e, lrc_handle, lrc_handle);
+	write_member(struct prelim_drm_xe_eudebug_event_exec_queue_placements, e, num_placements,
 		     num_placements);
 
 	memcpy(e->instances, instances, num_placements * sizeof(*instances));
@@ -2839,7 +2839,7 @@ static int exec_queue_create_events(struct xe_eudebug *d,
 	 * we disconnect
 	 */
 
-	ret = send_exec_queue_event(d, DRM_XE_EUDEBUG_EVENT_CREATE,
+	ret = send_exec_queue_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_CREATE,
 				  h_c, h_vm, h_queue, q->class,
 				  q->width, h_lrc, seqno);
 
@@ -2893,33 +2893,33 @@ static int exec_queue_destroy_event(struct xe_eudebug *d,
 		h_lrc[i] = ret;
 	}
 
-	return send_exec_queue_event(d, DRM_XE_EUDEBUG_EVENT_DESTROY,
+	return send_exec_queue_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_DESTROY,
 				     h_c, h_vm, h_queue, q->class,
 				     q->width, h_lrc, seqno);
 }
 
-void xe_eudebug_exec_queue_create(struct xe_file *xef, struct xe_exec_queue *q)
+void prelim_xe_eudebug_exec_queue_create(struct xe_file *xef, struct xe_exec_queue *q)
 {
 	struct xe_eudebug *d;
 
 	if (!exec_queue_class_is_tracked(q->class))
 		return;
 
-	d = xe_eudebug_get(xef);
+	d = prelim_xe_eudebug_get(xef);
 	if (!d)
 		return;
 
 	xe_eudebug_event_put(d, exec_queue_create_events(d, xef, q));
 }
 
-void xe_eudebug_exec_queue_destroy(struct xe_file *xef, struct xe_exec_queue *q)
+void prelim_xe_eudebug_exec_queue_destroy(struct xe_file *xef, struct xe_exec_queue *q)
 {
 	struct xe_eudebug *d;
 
 	if (!exec_queue_class_is_tracked(q->class))
 		return;
 
-	d = xe_eudebug_get(xef);
+	d = prelim_xe_eudebug_get(xef);
 	if (!d)
 		return;
 
@@ -2944,7 +2944,7 @@ static int xe_eudebug_queue_bind_event(struct xe_eudebug *d,
 	spin_lock(&vm->eudebug.lock);
 	list_add_tail(&env->link, &vm->eudebug.events);
 
-	if (event->type == DRM_XE_EUDEBUG_EVENT_VM_BIND_OP)
+	if (event->type == PRELIM_DRM_XE_EUDEBUG_EVENT_VM_BIND_OP)
 		++vm->eudebug.ops;
 	spin_unlock(&vm->eudebug.lock);
 
@@ -2961,20 +2961,20 @@ static int queue_vm_bind_event(struct xe_eudebug *d,
 	struct xe_eudebug_event_vm_bind *e;
 	struct xe_eudebug_event *event;
 	const u32 sz = sizeof(*e);
-	const u32 base_flags = DRM_XE_EUDEBUG_EVENT_STATE_CHANGE;
+	const u32 base_flags = PRELIM_DRM_XE_EUDEBUG_EVENT_STATE_CHANGE;
 
 	*seqno = atomic_long_inc_return(&d->events.seqno);
 
-	event = xe_eudebug_create_event(d, DRM_XE_EUDEBUG_EVENT_VM_BIND,
+	event = xe_eudebug_create_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_VM_BIND,
 					*seqno, base_flags, sz);
 	if (!event)
 		return -ENOMEM;
 
 	e = cast_event(e, event);
-	write_member(struct drm_xe_eudebug_event_vm_bind, e, client_handle, client_handle);
-	write_member(struct drm_xe_eudebug_event_vm_bind, e, vm_handle, vm_handle);
-	write_member(struct drm_xe_eudebug_event_vm_bind, e, flags, bind_flags);
-	write_member(struct drm_xe_eudebug_event_vm_bind, e, num_binds, num_ops);
+	write_member(struct prelim_drm_xe_eudebug_event_vm_bind, e, client_handle, client_handle);
+	write_member(struct prelim_drm_xe_eudebug_event_vm_bind, e, vm_handle, vm_handle);
+	write_member(struct prelim_drm_xe_eudebug_event_vm_bind, e, flags, bind_flags);
+	write_member(struct prelim_drm_xe_eudebug_event_vm_bind, e, num_binds, num_ops);
 
 	/* If in discovery, no need to collect ops */
 	if (!completion_done(&d->discovery)) {
@@ -3018,17 +3018,17 @@ static int vm_bind_op_event(struct xe_eudebug *d,
 
 	*op_seqno = atomic_long_inc_return(&d->events.seqno);
 
-	event = xe_eudebug_create_event(d, DRM_XE_EUDEBUG_EVENT_VM_BIND_OP,
+	event = xe_eudebug_create_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_VM_BIND_OP,
 					*op_seqno, flags, sz);
 	if (!event)
 		return -ENOMEM;
 
 	e = cast_event(e, event);
 
-	write_member(struct drm_xe_eudebug_event_vm_bind_op, e, vm_bind_ref_seqno, bind_ref_seqno);
-	write_member(struct drm_xe_eudebug_event_vm_bind_op, e, num_extensions, num_extensions);
-	write_member(struct drm_xe_eudebug_event_vm_bind_op, e, addr, addr);
-	write_member(struct drm_xe_eudebug_event_vm_bind_op, e, range, range);
+	write_member(struct prelim_drm_xe_eudebug_event_vm_bind_op, e, vm_bind_ref_seqno, bind_ref_seqno);
+	write_member(struct prelim_drm_xe_eudebug_event_vm_bind_op, e, num_extensions, num_extensions);
+	write_member(struct prelim_drm_xe_eudebug_event_vm_bind_op, e, addr, addr);
+	write_member(struct prelim_drm_xe_eudebug_event_vm_bind_op, e, range, range);
 
 	/* If in discovery, no need to collect ops */
 	if (!completion_done(&d->discovery))
@@ -3051,18 +3051,18 @@ static int vm_bind_op_metadata_event(struct xe_eudebug *d,
 
 	seqno = atomic_long_inc_return(&d->events.seqno);
 
-	event = xe_eudebug_create_event(d, DRM_XE_EUDEBUG_EVENT_VM_BIND_OP_METADATA,
+	event = xe_eudebug_create_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_VM_BIND_OP_METADATA,
 					seqno, flags, sz);
 	if (!event)
 		return -ENOMEM;
 
 	e = cast_event(e, event);
 
-	write_member(struct drm_xe_eudebug_event_vm_bind_op_metadata, e,
+	write_member(struct prelim_drm_xe_eudebug_event_vm_bind_op_metadata, e,
 		     vm_bind_op_ref_seqno, ref_seqno);
-	write_member(struct drm_xe_eudebug_event_vm_bind_op_metadata, e,
+	write_member(struct prelim_drm_xe_eudebug_event_vm_bind_op_metadata, e,
 		     metadata_handle, metadata_handle);
-	write_member(struct drm_xe_eudebug_event_vm_bind_op_metadata, e,
+	write_member(struct prelim_drm_xe_eudebug_event_vm_bind_op_metadata, e,
 		     metadata_cookie, metadata_cookie);
 
 	/* If in discovery, no need to collect ops */
@@ -3077,17 +3077,17 @@ static int vm_bind_op_metadata_count(struct xe_eudebug *d,
 				     struct list_head *debug_metadata)
 {
 	struct xe_vma_debug_metadata *metadata;
-	struct xe_debug_metadata *mdata;
+	struct prelim_xe_debug_metadata *mdata;
 	int h_m = 0, metadata_count = 0;
 
 	if (!debug_metadata)
 		return 0;
 
 	list_for_each_entry(metadata, debug_metadata, link) {
-		mdata = xe_debug_metadata_get(vm->xef, metadata->metadata_id);
+		mdata = prelim_xe_debug_metadata_get(vm->xef, metadata->metadata_id);
 		if (mdata) {
 			h_m = find_handle(d->res, XE_EUDEBUG_RES_TYPE_METADATA, mdata);
-			xe_debug_metadata_put(mdata);
+			prelim_xe_debug_metadata_put(mdata);
 		}
 
 		if (!mdata || h_m < 0) {
@@ -3119,15 +3119,15 @@ static int vm_bind_op_metadata(struct xe_eudebug *d, struct xe_vm *vm,
 	if (!debug_metadata)
 		return 0;
 
-	XE_WARN_ON(flags != DRM_XE_EUDEBUG_EVENT_CREATE);
+	XE_WARN_ON(flags != PRELIM_DRM_XE_EUDEBUG_EVENT_CREATE);
 
 	list_for_each_entry(metadata, debug_metadata, link) {
-		struct xe_debug_metadata *mdata;
+		struct prelim_xe_debug_metadata *mdata;
 
-		mdata = xe_debug_metadata_get(vm->xef, metadata->metadata_id);
+		mdata = prelim_xe_debug_metadata_get(vm->xef, metadata->metadata_id);
 		if (mdata) {
 			h_m = find_handle(d->res, XE_EUDEBUG_RES_TYPE_METADATA, mdata);
-			xe_debug_metadata_put(mdata);
+			prelim_xe_debug_metadata_put(mdata);
 		}
 
 		if (!mdata || h_m < 0) {
@@ -3219,21 +3219,21 @@ static int vm_bind_ufence_event(struct xe_eudebug *d,
 	struct xe_eudebug_event *event;
 	struct xe_eudebug_event_vm_bind_ufence *e;
 	const u32 sz = sizeof(*e);
-	const u32 flags = DRM_XE_EUDEBUG_EVENT_CREATE |
-		DRM_XE_EUDEBUG_EVENT_NEED_ACK;
+	const u32 flags = PRELIM_DRM_XE_EUDEBUG_EVENT_CREATE |
+		PRELIM_DRM_XE_EUDEBUG_EVENT_NEED_ACK;
 	u64 seqno;
 	int ret;
 
 	seqno = atomic_long_inc_return(&d->events.seqno);
 
-	event = xe_eudebug_create_event(d, DRM_XE_EUDEBUG_EVENT_VM_BIND_UFENCE,
+	event = xe_eudebug_create_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_VM_BIND_UFENCE,
 					seqno, flags, sz);
 	if (!event)
 		return -ENOMEM;
 
 	e = cast_event(e, event);
 
-	write_member(struct drm_xe_eudebug_event_vm_bind_ufence,
+	write_member(struct prelim_drm_xe_eudebug_event_vm_bind_ufence,
 		     e, vm_bind_ref_seqno, ufence->eudebug.bind_ref_seqno);
 
 	ret = xe_eudebug_track_ufence(d, ufence, seqno);
@@ -3243,7 +3243,7 @@ static int vm_bind_ufence_event(struct xe_eudebug *d,
 	return ret;
 }
 
-void xe_eudebug_vm_init(struct xe_vm *vm)
+void prelim_xe_eudebug_vm_init(struct xe_vm *vm)
 {
 	INIT_LIST_HEAD(&vm->eudebug.events);
 	spin_lock_init(&vm->eudebug.lock);
@@ -3251,7 +3251,7 @@ void xe_eudebug_vm_init(struct xe_vm *vm)
 	vm->eudebug.ref_seqno = 0;
 }
 
-void xe_eudebug_vm_bind_start(struct xe_vm *vm)
+void prelim_xe_eudebug_vm_bind_start(struct xe_vm *vm)
 {
 	struct xe_eudebug *d;
 	u64 seqno = 0;
@@ -3260,7 +3260,7 @@ void xe_eudebug_vm_bind_start(struct xe_vm *vm)
 	if (!xe_vm_in_lr_mode(vm))
 		return;
 
-	d = xe_eudebug_get(vm->xef);
+	d = prelim_xe_eudebug_get(vm->xef);
 	if (!d)
 		return;
 
@@ -3285,10 +3285,10 @@ void xe_eudebug_vm_bind_start(struct xe_vm *vm)
 	vm->eudebug.ops = 0;
 	spin_unlock(&vm->eudebug.lock);
 
-	xe_eudebug_put(d);
+	prelim_xe_eudebug_put(d);
 }
 
-void xe_eudebug_vm_bind_op_add(struct xe_vm *vm, u32 op, u64 addr, u64 range,
+void prelim_xe_eudebug_vm_bind_op_add(struct xe_vm *vm, u32 op, u64 addr, u64 range,
 			       struct drm_gpuva_ops *ops)
 {
 	struct xe_eudebug *d;
@@ -3304,7 +3304,7 @@ void xe_eudebug_vm_bind_op_add(struct xe_vm *vm, u32 op, u64 addr, u64 range,
 	{
 		struct drm_gpuva_op *__op;
 
-		flags = DRM_XE_EUDEBUG_EVENT_CREATE;
+		flags = PRELIM_DRM_XE_EUDEBUG_EVENT_CREATE;
 
 		/* OP_MAP will be last and singleton */
 		drm_gpuva_for_each_op(__op, ops) {
@@ -3317,7 +3317,7 @@ void xe_eudebug_vm_bind_op_add(struct xe_vm *vm, u32 op, u64 addr, u64 range,
 	}
 	case DRM_XE_VM_BIND_OP_UNMAP:
 	case DRM_XE_VM_BIND_OP_UNMAP_ALL:
-		flags = DRM_XE_EUDEBUG_EVENT_DESTROY;
+		flags = PRELIM_DRM_XE_EUDEBUG_EVENT_DESTROY;
 		break;
 	default:
 		flags = 0;
@@ -3327,7 +3327,7 @@ void xe_eudebug_vm_bind_op_add(struct xe_vm *vm, u32 op, u64 addr, u64 range,
 	if (!flags)
 		return;
 
-	d = xe_eudebug_get(vm->xef);
+	d = prelim_xe_eudebug_get(vm->xef);
 	if (!d)
 		return;
 
@@ -3362,7 +3362,7 @@ static void fill_vm_bind_fields(struct xe_vm *vm,
 	struct xe_eudebug_event_vm_bind *eb = cast_event(eb, e);
 
 	eb->flags = ufence ?
-		DRM_XE_EUDEBUG_EVENT_VM_BIND_FLAG_UFENCE : 0;
+		PRELIM_DRM_XE_EUDEBUG_EVENT_VM_BIND_FLAG_UFENCE : 0;
 	eb->num_binds = bind_ops;
 }
 
@@ -3372,14 +3372,14 @@ static void fill_vm_bind_op_fields(struct xe_vm *vm,
 {
 	struct xe_eudebug_event_vm_bind_op *op;
 
-	if (e->type != DRM_XE_EUDEBUG_EVENT_VM_BIND_OP)
+	if (e->type != PRELIM_DRM_XE_EUDEBUG_EVENT_VM_BIND_OP)
 		return;
 
 	op = cast_event(op, e);
 	op->vm_bind_ref_seqno = ref_seqno;
 }
 
-void xe_eudebug_vm_bind_end(struct xe_vm *vm, bool has_ufence, int bind_err)
+void prelim_xe_eudebug_vm_bind_end(struct xe_vm *vm, bool has_ufence, int bind_err)
 {
 	struct xe_eudebug_event *e;
 	struct xe_eudebug *d;
@@ -3402,7 +3402,7 @@ void xe_eudebug_vm_bind_end(struct xe_vm *vm, bool has_ufence, int bind_err)
 
 	d = NULL;
 	if (!bind_err && ref) {
-		d = xe_eudebug_get(vm->xef);
+		d = prelim_xe_eudebug_get(vm->xef);
 		if (d) {
 			if (bind_ops) {
 				fill_vm_bind_fields(vm, e, has_ufence, bind_ops);
@@ -3411,7 +3411,7 @@ void xe_eudebug_vm_bind_end(struct xe_vm *vm, bool has_ufence, int bind_err)
 				 * If there was no ops we are interested in,
 				 * we can omit the whole sequence
 				 */
-				xe_eudebug_put(d);
+				prelim_xe_eudebug_put(d);
 				d = NULL;
 			}
 		}
@@ -3428,7 +3428,7 @@ void xe_eudebug_vm_bind_end(struct xe_vm *vm, bool has_ufence, int bind_err)
 
 		if (err) {
 			xe_eudebug_disconnect(d, err);
-			xe_eudebug_put(d);
+			prelim_xe_eudebug_put(d);
 			d = NULL;
 		}
 
@@ -3440,10 +3440,10 @@ void xe_eudebug_vm_bind_end(struct xe_vm *vm, bool has_ufence, int bind_err)
 	}
 
 	if (d)
-		xe_eudebug_put(d);
+		prelim_xe_eudebug_put(d);
 }
 
-int xe_eudebug_vm_bind_ufence(struct xe_user_fence *ufence)
+int prelim_xe_eudebug_vm_bind_ufence(struct xe_user_fence *ufence)
 {
 	struct xe_eudebug *d;
 	int err;
@@ -3468,23 +3468,23 @@ static int send_debug_metadata_event(struct xe_eudebug *d, u32 flags,
 	struct xe_eudebug_event *event;
 	struct xe_eudebug_event_metadata *e;
 
-	event = xe_eudebug_create_event(d, DRM_XE_EUDEBUG_EVENT_METADATA, seqno,
+	event = xe_eudebug_create_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_METADATA, seqno,
 					flags, sizeof(*e));
 	if (!event)
 		return -ENOMEM;
 
 	e = cast_event(e, event);
 
-	write_member(struct drm_xe_eudebug_event_metadata, e, client_handle, client_handle);
-	write_member(struct drm_xe_eudebug_event_metadata, e, metadata_handle, metadata_handle);
-	write_member(struct drm_xe_eudebug_event_metadata, e, type, type);
-	write_member(struct drm_xe_eudebug_event_metadata, e, len, len);
+	write_member(struct prelim_drm_xe_eudebug_event_metadata, e, client_handle, client_handle);
+	write_member(struct prelim_drm_xe_eudebug_event_metadata, e, metadata_handle, metadata_handle);
+	write_member(struct prelim_drm_xe_eudebug_event_metadata, e, type, type);
+	write_member(struct prelim_drm_xe_eudebug_event_metadata, e, len, len);
 
 	return xe_eudebug_queue_event(d, event);
 }
 
 static int debug_metadata_create_event(struct xe_eudebug *d,
-				       struct xe_file *xef, struct xe_debug_metadata *m)
+				       struct xe_file *xef, struct prelim_xe_debug_metadata *m)
 {
 	int h_c, h_m;
 	u64 seqno;
@@ -3497,12 +3497,12 @@ static int debug_metadata_create_event(struct xe_eudebug *d,
 	if (h_m <= 0)
 		return h_m;
 
-	return send_debug_metadata_event(d, DRM_XE_EUDEBUG_EVENT_CREATE,
+	return send_debug_metadata_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_CREATE,
 					 h_c, h_m, m->type, m->len, seqno);
 }
 
 static int debug_metadata_destroy_event(struct xe_eudebug *d,
-					struct xe_file *xef, struct xe_debug_metadata *m)
+					struct xe_file *xef, struct prelim_xe_debug_metadata *m)
 {
 	int h_c, h_m;
 	u64 seqno;
@@ -3515,26 +3515,26 @@ static int debug_metadata_destroy_event(struct xe_eudebug *d,
 	if (h_m < 0)
 		return h_m;
 
-	return send_debug_metadata_event(d, DRM_XE_EUDEBUG_EVENT_DESTROY,
+	return send_debug_metadata_event(d, PRELIM_DRM_XE_EUDEBUG_EVENT_DESTROY,
 					 h_c, h_m, m->type, m->len, seqno);
 }
 
-void xe_eudebug_debug_metadata_create(struct xe_file *xef, struct xe_debug_metadata *m)
+void prelim_xe_eudebug_debug_metadata_create(struct xe_file *xef, struct prelim_xe_debug_metadata *m)
 {
 	struct xe_eudebug *d;
 
-	d = xe_eudebug_get(xef);
+	d = prelim_xe_eudebug_get(xef);
 	if (!d)
 		return;
 
 	xe_eudebug_event_put(d, debug_metadata_create_event(d, xef, m));
 }
 
-void xe_eudebug_debug_metadata_destroy(struct xe_file *xef, struct xe_debug_metadata *m)
+void prelim_xe_eudebug_debug_metadata_destroy(struct xe_file *xef, struct prelim_xe_debug_metadata *m)
 {
 	struct xe_eudebug *d;
 
-	d = xe_eudebug_get(xef);
+	d = prelim_xe_eudebug_get(xef);
 	if (!d)
 		return;
 
@@ -3570,7 +3570,7 @@ static int vm_discover_binds(struct xe_eudebug *d, struct xe_vm *vm)
 		if (send_ops >= num_ops)
 			break;
 
-		err = vm_bind_op(d, vm, DRM_XE_EUDEBUG_EVENT_CREATE, ref_seqno,
+		err = vm_bind_op(d, vm, PRELIM_DRM_XE_EUDEBUG_EVENT_CREATE, ref_seqno,
 				 xe_vma_start(vma), xe_vma_size(vma),
 				 &vma->eudebug.metadata.list);
 		if (err)
@@ -3584,7 +3584,7 @@ static int vm_discover_binds(struct xe_eudebug *d, struct xe_vm *vm)
 
 static int discover_client(struct xe_eudebug *d, struct xe_file *xef)
 {
-	struct xe_debug_metadata *m;
+	struct prelim_xe_debug_metadata *m;
 	struct xe_exec_queue *q;
 	struct xe_vm *vm;
 	unsigned long i;
@@ -3667,7 +3667,7 @@ static void discovery_work_fn(struct work_struct *work)
 
 	if (xe_eudebug_detached(d)) {
 		complete_all(&d->discovery);
-		xe_eudebug_put(d);
+		prelim_xe_eudebug_put(d);
 		return;
 	}
 
@@ -3685,10 +3685,10 @@ static void discovery_work_fn(struct work_struct *work)
 
 	send_queued_pagefault(d, false);
 
-	xe_eudebug_put(d);
+	prelim_xe_eudebug_put(d);
 }
 
-void xe_eudebug_ufence_init(struct xe_user_fence *ufence,
+void prelim_xe_eudebug_ufence_init(struct xe_user_fence *ufence,
 			    struct xe_file *xef,
 			    struct xe_vm *vm)
 {
@@ -3708,19 +3708,19 @@ void xe_eudebug_ufence_init(struct xe_user_fence *ufence,
 	ufence->eudebug.signalled_seqno = 0;
 
 	if (bind_ref) {
-		ufence->eudebug.debugger = xe_eudebug_get(xef);
+		ufence->eudebug.debugger = prelim_xe_eudebug_get(xef);
 
 		if (ufence->eudebug.debugger)
 			ufence->eudebug.bind_ref_seqno = bind_ref;
 	}
 }
 
-void xe_eudebug_ufence_fini(struct xe_user_fence *ufence)
+void prelim_xe_eudebug_ufence_fini(struct xe_user_fence *ufence)
 {
 	if (!ufence->eudebug.debugger)
 		return;
 
-	xe_eudebug_put(ufence->eudebug.debugger);
+	prelim_xe_eudebug_put(ufence->eudebug.debugger);
 	ufence->eudebug.debugger = NULL;
 }
 
@@ -4035,7 +4035,7 @@ static int xe_eudebug_vm_release(struct inode *inode, struct file *file)
 
 	xe_vm_put(vmf->vm);
 	xe_file_put(vmf->xef);
-	xe_eudebug_put(d);
+	prelim_xe_eudebug_put(d);
 	drm_dev_put(&d->xe->drm);
 
 	kfree(vmf);
@@ -4056,8 +4056,8 @@ static const struct file_operations vm_fops = {
 static long
 xe_eudebug_vm_open_ioctl(struct xe_eudebug *d, unsigned long arg)
 {
-	const u64 max_timeout_ns = DRM_XE_EUDEBUG_VM_SYNC_MAX_TIMEOUT_NSECS;
-	struct drm_xe_eudebug_vm_open param;
+	const u64 max_timeout_ns = PRELIM_DRM_XE_EUDEBUG_VM_SYNC_MAX_TIMEOUT_NSECS;
+	struct prelim_drm_xe_eudebug_vm_open param;
 	struct xe_device * const xe = d->xe;
 	struct vm_file *vmf = NULL;
 	struct xe_file *xef;
@@ -4066,10 +4066,10 @@ xe_eudebug_vm_open_ioctl(struct xe_eudebug *d, unsigned long arg)
 	long ret = 0;
 	int fd;
 
-	if (XE_IOCTL_DBG(xe, _IOC_SIZE(DRM_XE_EUDEBUG_IOCTL_VM_OPEN) != sizeof(param)))
+	if (XE_IOCTL_DBG(xe, _IOC_SIZE(PRELIM_DRM_XE_EUDEBUG_IOCTL_VM_OPEN) != sizeof(param)))
 		return -EINVAL;
 
-	if (XE_IOCTL_DBG(xe, !(_IOC_DIR(DRM_XE_EUDEBUG_IOCTL_VM_OPEN) & _IOC_WRITE)))
+	if (XE_IOCTL_DBG(xe, !(_IOC_DIR(PRELIM_DRM_XE_EUDEBUG_IOCTL_VM_OPEN) & _IOC_WRITE)))
 		return -EINVAL;
 
 	if (XE_IOCTL_DBG(xe, copy_from_user(&param, (void __user *)arg, sizeof(param))))
@@ -4143,7 +4143,7 @@ xe_eudebug_vm_open_ioctl(struct xe_eudebug *d, unsigned long arg)
 
 out_fd_put:
 	put_unused_fd(fd);
-	xe_eudebug_put(d);
+	prelim_xe_eudebug_put(d);
 out_free:
 	kfree(vmf);
 out_vm_put:
@@ -4171,7 +4171,7 @@ static int queue_pagefault(struct xe_gt *gt, struct xe_eudebug_pagefault *pf)
 	list_add_tail(&pf->list, &d->pagefaults);
 	mutex_unlock(&d->pf_lock);
 
-	xe_eudebug_put(d);
+	prelim_xe_eudebug_put(d);
 
 	return 0;
 }
@@ -4237,7 +4237,7 @@ static struct pagefault_fence *pagefault_fence_create(void)
 }
 
 struct xe_eudebug_pagefault *
-xe_eudebug_pagefault_create(struct xe_gt *gt, struct xe_vm *vm, u64 page_addr,
+prelim_xe_eudebug_pagefault_create(struct xe_gt *gt, struct xe_vm *vm, u64 page_addr,
 			    u8 fault_type, u8 fault_level, u8 access_type)
 {
 	struct pagefault_fence *pf_fence;
@@ -4313,7 +4313,7 @@ xe_eudebug_pagefault_create(struct xe_gt *gt, struct xe_vm *vm, u64 page_addr,
 
 	INIT_LIST_HEAD(&pf->list);
 
-	xe_gt_eu_attentions_read(gt, &pf->attentions.before, 0);
+	prelim_xe_gt_eu_attentions_read(gt, &pf->attentions.before, 0);
 
 	/* Halt on next thread dispatch */
 	while (!(td_ctl & TD_CTL_FORCE_EXTERNAL_HALT)) {
@@ -4336,11 +4336,11 @@ xe_eudebug_pagefault_create(struct xe_gt *gt, struct xe_vm *vm, u64 page_addr,
 		td_ctl = xe_gt_mcr_unicast_read_any(gt, TD_CTL);
 	}
 
-	xe_gt_eu_attentions_read(gt, &pf->attentions.after,
-				 XE_GT_ATTENTION_TIMEOUT_MS);
+	prelim_xe_gt_eu_attentions_read(gt, &pf->attentions.after,
+				 PRELIM_XE_GT_ATTENTION_TIMEOUT_MS);
 
 	/*
-	 * xe_exec_queue_put() will be called from xe_eudebug_pagefault_destroy()
+	 * xe_exec_queue_put() will be called from prelim_xe_eudebug_pagefault_destroy()
 	 * or handle_pagefault()
 	 */
 	pf->q = q;
@@ -4351,7 +4351,7 @@ xe_eudebug_pagefault_create(struct xe_gt *gt, struct xe_vm *vm, u64 page_addr,
 	pf->fault.access = access_type;
 
 	xe_force_wake_put(gt_to_fw(gt), fw_ref);
-	xe_eudebug_put(d);
+	prelim_xe_eudebug_put(d);
 
 	return pf;
 
@@ -4364,16 +4364,16 @@ xe_eudebug_pagefault_create(struct xe_gt *gt, struct xe_vm *vm, u64 page_addr,
 err_put_exec_queue:
 	xe_exec_queue_put(q);
 err_put_eudebug:
-	xe_eudebug_put(d);
+	prelim_xe_eudebug_put(d);
 
 	return NULL;
 }
 
 void
-xe_eudebug_pagefault_process(struct xe_gt *gt, struct xe_eudebug_pagefault *pf)
+prelim_xe_eudebug_pagefault_process(struct xe_gt *gt, struct xe_eudebug_pagefault *pf)
 {
-	xe_gt_eu_attentions_read(gt, &pf->attentions.resolved,
-				 XE_GT_ATTENTION_TIMEOUT_MS);
+	prelim_xe_gt_eu_attentions_read(gt, &pf->attentions.resolved,
+				 PRELIM_XE_GT_ATTENTION_TIMEOUT_MS);
 
 	if (!xe_eu_attentions_xor_count(&pf->attentions.after,
 					&pf->attentions.resolved))
@@ -4381,7 +4381,7 @@ xe_eudebug_pagefault_process(struct xe_gt *gt, struct xe_eudebug_pagefault *pf)
 }
 
 void
-xe_eudebug_pagefault_destroy(struct xe_gt *gt, struct xe_vm *vm,
+prelim_xe_eudebug_pagefault_destroy(struct xe_gt *gt, struct xe_vm *vm,
 			     struct xe_eudebug_pagefault *pf, bool send_event)
 {
 	struct xe_eudebug *d;
@@ -4422,7 +4422,7 @@ xe_eudebug_pagefault_destroy(struct xe_gt *gt, struct xe_vm *vm,
 		d->pf_fence = NULL;
 		mutex_unlock(&d->eu_lock);
 
-		xe_eudebug_put(d);
+		prelim_xe_eudebug_put(d);
 	}
 
 	if (!send_event) {
diff --git a/drivers/gpu/drm/xe/prelim/xe_eudebug.h b/drivers/gpu/drm/xe/prelim/xe_eudebug.h
new file mode 100644
index 000000000..6c4423952
--- /dev/null
+++ b/drivers/gpu/drm/xe/prelim/xe_eudebug.h
@@ -0,0 +1,106 @@
+/* SPDX-License-Identifier: MIT */
+/*
+ * Copyright © 2023 Intel Corporation
+ */
+
+#ifndef _XE_EUDEBUG_H_
+
+#include <linux/types.h>
+
+struct drm_device;
+struct drm_file;
+struct xe_device;
+struct xe_file;
+struct xe_gt;
+struct xe_vm;
+struct xe_vma;
+struct xe_exec_queue;
+struct xe_hw_engine;
+struct xe_user_fence;
+struct prelim_xe_debug_metadata;
+struct drm_gpuva_ops;
+struct xe_eudebug_pagefault;
+
+#if IS_ENABLED(CONFIG_PRELIM_DRM_XE_EUDEBUG)
+
+int prelim_xe_eudebug_connect_ioctl(struct drm_device *dev,
+			     void *data,
+			     struct drm_file *file);
+
+void prelim_xe_eudebug_init(struct xe_device *xe);
+void prelim_xe_eudebug_fini(struct xe_device *xe);
+
+void prelim_xe_eudebug_file_open(struct xe_file *xef);
+void prelim_xe_eudebug_file_close(struct xe_file *xef);
+
+void prelim_xe_eudebug_vm_create(struct xe_file *xef, struct xe_vm *vm);
+void prelim_xe_eudebug_vm_destroy(struct xe_file *xef, struct xe_vm *vm);
+
+void prelim_xe_eudebug_exec_queue_create(struct xe_file *xef, struct xe_exec_queue *q);
+void prelim_xe_eudebug_exec_queue_destroy(struct xe_file *xef, struct xe_exec_queue *q);
+
+void prelim_xe_eudebug_vm_init(struct xe_vm *vm);
+void prelim_xe_eudebug_vm_bind_start(struct xe_vm *vm);
+void prelim_xe_eudebug_vm_bind_op_add(struct xe_vm *vm, u32 op, u64 addr, u64 range,
+			       struct drm_gpuva_ops *ops);
+void prelim_xe_eudebug_vm_bind_end(struct xe_vm *vm, bool has_ufence, int err);
+
+int prelim_xe_eudebug_vm_bind_ufence(struct xe_user_fence *ufence);
+void prelim_xe_eudebug_ufence_init(struct xe_user_fence *ufence, struct xe_file *xef, struct xe_vm *vm);
+void prelim_xe_eudebug_ufence_fini(struct xe_user_fence *ufence);
+
+struct xe_eudebug *prelim_xe_eudebug_get(struct xe_file *xef);
+void prelim_xe_eudebug_put(struct xe_eudebug *d);
+
+void prelim_xe_eudebug_debug_metadata_create(struct xe_file *xef, struct prelim_xe_debug_metadata *m);
+void prelim_xe_eudebug_debug_metadata_destroy(struct xe_file *xef, struct prelim_xe_debug_metadata *m);
+
+struct xe_eudebug_pagefault *prelim_xe_eudebug_pagefault_create(struct xe_gt *gt, struct xe_vm *vm,
+							 u64 page_addr, u8 fault_type,
+							 u8 fault_level, u8 access_type);
+void prelim_xe_eudebug_pagefault_process(struct xe_gt *gt, struct xe_eudebug_pagefault *pf);
+void prelim_xe_eudebug_pagefault_destroy(struct xe_gt *gt, struct xe_vm *vm,
+				  struct xe_eudebug_pagefault *pf, bool send_event);
+
+#else
+
+static inline int prelim_xe_eudebug_connect_ioctl(struct drm_device *dev,
+					   void *data,
+					   struct drm_file *file) { return 0; }
+
+static inline void prelim_xe_eudebug_init(struct xe_device *xe) { }
+static inline void prelim_xe_eudebug_fini(struct xe_device *xe) { }
+
+static inline void prelim_xe_eudebug_file_open(struct xe_file *xef) { }
+static inline void prelim_xe_eudebug_file_close(struct xe_file *xef) { }
+
+static inline void prelim_xe_eudebug_vm_create(struct xe_file *xef, struct xe_vm *vm) { }
+static inline void prelim_xe_eudebug_vm_destroy(struct xe_file *xef, struct xe_vm *vm) { }
+
+static inline void prelim_xe_eudebug_exec_queue_create(struct xe_file *xef, struct xe_exec_queue *q) { }
+static inline void prelim_xe_eudebug_exec_queue_destroy(struct xe_file *xef, struct xe_exec_queue *q) { }
+
+static inline void prelim_xe_eudebug_vm_init(struct xe_vm *vm) { }
+static inline void prelim_xe_eudebug_vm_bind_start(struct xe_vm *vm) { }
+static inline void prelim_xe_eudebug_vm_bind_op_add(struct xe_vm *vm, u32 op, u64 addr, u64 range, struct drm_gpuva_ops *ops) { }
+static inline void prelim_xe_eudebug_vm_bind_end(struct xe_vm *vm, bool has_ufence, int err) { }
+
+static inline int prelim_xe_eudebug_vm_bind_ufence(struct xe_user_fence *ufence) { return 0; }
+static inline void prelim_xe_eudebug_ufence_init(struct xe_user_fence *ufence, struct xe_file *xef, struct xe_vm *vm) { }
+static inline void prelim_xe_eudebug_ufence_fini(struct xe_user_fence *ufence) { }
+
+static inline struct xe_eudebug *prelim_xe_eudebug_get(struct xe_file *xef) { return NULL; }
+static inline void prelim_xe_eudebug_put(struct xe_eudebug *d) { }
+
+static inline void prelim_xe_eudebug_debug_metadata_create(struct xe_file *xef, struct xe_debug_metadata *m) { }
+static inline void prelim_xe_eudebug_debug_metadata_destroy(struct xe_file *xef, struct xe_debug_metadata *m) { }
+
+static inline struct xe_eudebug_pagefault *prelim_xe_eudebug_pagefault_create(struct xe_gt *gt, struct xe_vm *vm,
+								       u64 page_addr, u8 fault_type,
+								       u8 fault_level, u8 access_type) { return NULL; }
+static inline void prelim_xe_eudebug_pagefault_process(struct xe_gt *gt, struct xe_eudebug_pagefault *pf) { }
+static inline void prelim_xe_eudebug_pagefault_destroy(struct xe_gt *gt, struct xe_vm *vm, struct xe_eudebug_pagefault *pf, bool send_event) { }
+
+#endif /* CONFIG_PRELIM_DRM_XE_EUDEBUG */
+
+#endif
diff --git a/drivers/gpu/drm/xe/xe_eudebug_types.h b/drivers/gpu/drm/xe/prelim/xe_eudebug_types.h
similarity index 99%
rename from drivers/gpu/drm/xe/xe_eudebug_types.h
rename to drivers/gpu/drm/xe/prelim/xe_eudebug_types.h
index 00853dacd..e3a028973 100644
--- a/drivers/gpu/drm/xe/xe_eudebug_types.h
+++ b/drivers/gpu/drm/xe/prelim/xe_eudebug_types.h
@@ -4,6 +4,7 @@
  */
 
 #ifndef __XE_EUDEBUG_TYPES_H_
+#define __XE_EUDEBUG_TYPES_H_
 
 #include <linux/completion.h>
 #include <linux/kfifo.h>
diff --git a/drivers/gpu/drm/xe/xe_gt_debug.c b/drivers/gpu/drm/xe/prelim/xe_gt_debug.c
similarity index 77%
rename from drivers/gpu/drm/xe/xe_gt_debug.c
rename to drivers/gpu/drm/xe/prelim/xe_gt_debug.c
index 5dcc12ea5..1a17a8dd2 100644
--- a/drivers/gpu/drm/xe/xe_gt_debug.c
+++ b/drivers/gpu/drm/xe/prelim/xe_gt_debug.c
@@ -14,7 +14,7 @@
 #include "xe_pm.h"
 #include "xe_macros.h"
 
-int xe_gt_foreach_dss_group_instance(struct xe_gt *gt,
+int prelim_xe_gt_foreach_dss_group_instance(struct xe_gt *gt,
 				     int (*fn)(struct xe_gt *gt,
 					       void *data,
 					       u16 group,
@@ -62,13 +62,13 @@ static int read_first_attention_mcr(struct xe_gt *gt, void *data,
 #define MAX_THREADS 8u
 
 /**
- * xe_gt_eu_attention_bitmap_size - query size of the attention bitmask
+ * prelim_xe_gt_eu_attention_bitmap_size - query size of the attention bitmask
  *
  * @gt: pointer to struct xe_gt
  *
  * Return: size in bytes.
  */
-int xe_gt_eu_attention_bitmap_size(struct xe_gt *gt)
+int prelim_xe_gt_eu_attention_bitmap_size(struct xe_gt *gt)
 {
 	xe_dss_mask_t dss_mask;
 
@@ -76,7 +76,7 @@ int xe_gt_eu_attention_bitmap_size(struct xe_gt *gt)
 		  gt->fuse_topo.g_dss_mask, XE_MAX_DSS_FUSE_BITS);
 
 	return  bitmap_weight(dss_mask, XE_MAX_DSS_FUSE_BITS) *
-		TD_EU_ATTENTION_MAX_ROWS * MAX_THREADS *
+		PRELIM_TD_EU_ATTENTION_MAX_ROWS * MAX_THREADS *
 		MAX_EUS_PER_ROW / 8;
 }
 
@@ -93,13 +93,13 @@ static int read_eu_attentions_mcr(struct xe_gt *gt, void *data,
 	struct attn_read_iter * const iter = data;
 	unsigned int row;
 
-	for (row = 0; row < TD_EU_ATTENTION_MAX_ROWS; row++) {
+	for (row = 0; row < PRELIM_TD_EU_ATTENTION_MAX_ROWS; row++) {
 		u32 val;
 
 		if (iter->i >= iter->size)
 			return 0;
 
-		XE_WARN_ON(iter->i + sizeof(val) > xe_gt_eu_attention_bitmap_size(gt));
+		XE_WARN_ON(iter->i + sizeof(val) > prelim_xe_gt_eu_attention_bitmap_size(gt));
 
 		val = xe_gt_mcr_unicast_read(gt, TD_ATT(row), group, instance);
 
@@ -111,13 +111,13 @@ static int read_eu_attentions_mcr(struct xe_gt *gt, void *data,
 }
 
 /**
- * xe_gt_eu_attention_bitmap - query host attention
+ * prelim_xe_gt_eu_attention_bitmap - query host attention
  *
  * @gt: pointer to struct xe_gt
  *
  * Return: 0 on success, negative otherwise.
  */
-int xe_gt_eu_attention_bitmap(struct xe_gt *gt, u8 *bits,
+int prelim_xe_gt_eu_attention_bitmap(struct xe_gt *gt, u8 *bits,
 			      unsigned int bitmap_size)
 {
 	struct attn_read_iter iter = {
@@ -127,21 +127,21 @@ int xe_gt_eu_attention_bitmap(struct xe_gt *gt, u8 *bits,
 		.bits = bits
 	};
 
-	return xe_gt_foreach_dss_group_instance(gt, read_eu_attentions_mcr, &iter);
+	return prelim_xe_gt_foreach_dss_group_instance(gt, read_eu_attentions_mcr, &iter);
 }
 
 /**
- * xe_gt_eu_threads_needing_attention - Query host attention
+ * prelim_xe_gt_eu_threads_needing_attention - Query host attention
  *
  * @gt: pointer to struct xe_gt
  *
  * Return: 1 if threads waiting host attention, 0 otherwise.
  */
-int xe_gt_eu_threads_needing_attention(struct xe_gt *gt)
+int prelim_xe_gt_eu_threads_needing_attention(struct xe_gt *gt)
 {
 	int err;
 
-	err = xe_gt_foreach_dss_group_instance(gt, read_first_attention_mcr, NULL);
+	err = prelim_xe_gt_foreach_dss_group_instance(gt, read_first_attention_mcr, NULL);
 
 	XE_WARN_ON(err < 0);
 
@@ -154,7 +154,7 @@ xe_eu_attentions_count(const struct xe_eu_attentions *a)
 	return bitmap_weight((void *)a->att, a->size * BITS_PER_BYTE);
 }
 
-void xe_gt_eu_attentions_read(struct xe_gt *gt,
+void prelim_xe_gt_eu_attentions_read(struct xe_gt *gt,
 			      struct xe_eu_attentions *a,
 			      const unsigned int settle_time_ms)
 {
@@ -166,13 +166,13 @@ void xe_gt_eu_attentions_read(struct xe_gt *gt,
 
 	a->ts = 0;
 	a->size = min_t(int,
-			xe_gt_eu_attention_bitmap_size(gt),
+			prelim_xe_gt_eu_attention_bitmap_size(gt),
 			sizeof(a->att));
 
 	do {
 		unsigned int attn;
 
-		xe_gt_eu_attention_bitmap(gt, a->att, a->size);
+		prelim_xe_gt_eu_attention_bitmap(gt, a->att, a->size);
 		attn = xe_eu_attentions_count(a);
 
 		now = ktime_get_raw();
diff --git a/drivers/gpu/drm/xe/xe_gt_debug.h b/drivers/gpu/drm/xe/prelim/xe_gt_debug.h
similarity index 52%
rename from drivers/gpu/drm/xe/xe_gt_debug.h
rename to drivers/gpu/drm/xe/prelim/xe_gt_debug.h
index 3e3fb501e..619a94fee 100644
--- a/drivers/gpu/drm/xe/xe_gt_debug.h
+++ b/drivers/gpu/drm/xe/prelim/xe_gt_debug.h
@@ -6,34 +6,34 @@
 #ifndef __XE_GT_DEBUG_
 #define __XE_GT_DEBUG_
 
-#define TD_EU_ATTENTION_MAX_ROWS 2u
+#define PRELIM_TD_EU_ATTENTION_MAX_ROWS 2u
 
 #include "xe_gt_types.h"
 
-#define XE_GT_ATTENTION_TIMEOUT_MS 100
+#define PRELIM_XE_GT_ATTENTION_TIMEOUT_MS 100
 
 struct xe_eu_attentions {
-#define XE_MAX_EUS 1024
-#define XE_MAX_THREADS 10
+#define PRELIM_XE_MAX_EUS 1024
+#define PRELIM_XE_MAX_THREADS 10
 
-	u8 att[DIV_ROUND_UP(XE_MAX_EUS * XE_MAX_THREADS, BITS_PER_BYTE)];
+	u8 att[DIV_ROUND_UP(PRELIM_XE_MAX_EUS * PRELIM_XE_MAX_THREADS, BITS_PER_BYTE)];
 	unsigned int size;
 	ktime_t ts;
 };
 
-int xe_gt_eu_threads_needing_attention(struct xe_gt *gt);
-int xe_gt_foreach_dss_group_instance(struct xe_gt *gt,
+int prelim_xe_gt_eu_threads_needing_attention(struct xe_gt *gt);
+int prelim_xe_gt_foreach_dss_group_instance(struct xe_gt *gt,
 				     int (*fn)(struct xe_gt *gt,
 					       void *data,
 					       u16 group,
 					       u16 instance),
 				     void *data);
 
-int xe_gt_eu_attention_bitmap_size(struct xe_gt *gt);
-int xe_gt_eu_attention_bitmap(struct xe_gt *gt, u8 *bits,
+int prelim_xe_gt_eu_attention_bitmap_size(struct xe_gt *gt);
+int prelim_xe_gt_eu_attention_bitmap(struct xe_gt *gt, u8 *bits,
 			      unsigned int bitmap_size);
 
-void xe_gt_eu_attentions_read(struct xe_gt *gt,
+void prelim_xe_gt_eu_attentions_read(struct xe_gt *gt,
 			      struct xe_eu_attentions *a,
 			      const unsigned int settle_time_ms);
 
diff --git a/drivers/gpu/drm/xe/xe_device.c b/drivers/gpu/drm/xe/xe_device.c
index 037cae190..a6344cf14 100644
--- a/drivers/gpu/drm/xe/xe_device.c
+++ b/drivers/gpu/drm/xe/xe_device.c
@@ -26,11 +26,10 @@
 #include "xe_debugfs.h"
 #include "xe_devcoredump.h"
 #include "xe_device_sysfs.h"
-#include "xe_debug_metadata.h"
+#include "prelim/xe_debug_metadata.h"
 #include "xe_dma_buf.h"
 #include "xe_drm_client.h"
 #include "xe_drv.h"
-#include "xe_eudebug.h"
 #include "xe_exec.h"
 #include "xe_exec_queue.h"
 #include "xe_force_wake.h"
@@ -67,6 +66,7 @@
 #include "xe_wait_user_fence.h"
 #include "xe_wa.h"
 
+#include "prelim/xe_eudebug.h"
 #include <generated/xe_wa_oob.h>
 
 static int xe_file_open(struct drm_device *dev, struct drm_file *file)
@@ -107,7 +107,7 @@ static int xe_file_open(struct drm_device *dev, struct drm_file *file)
 		put_task_struct(task);
 	}
 
-	xe_eudebug_file_open(xef);
+	prelim_xe_eudebug_file_open(xef);
 
 	return 0;
 }
@@ -162,7 +162,7 @@ static void xe_file_close(struct drm_device *dev, struct drm_file *file)
 
 	xe_pm_runtime_get(xe);
 
-	xe_eudebug_file_close(xef);
+	prelim_xe_eudebug_file_close(xef);
 
 	/*
 	 * No need for exec_queue.lock here as there is no contention for it
@@ -210,10 +210,10 @@ static const struct drm_ioctl_desc xe_ioctls[] = {
 	DRM_IOCTL_DEF_DRV(XE_WAIT_USER_FENCE, xe_wait_user_fence_ioctl,
 			  DRM_RENDER_ALLOW),
 	DRM_IOCTL_DEF_DRV(XE_OBSERVATION, xe_observation_ioctl, DRM_RENDER_ALLOW),
-	DRM_IOCTL_DEF_DRV(XE_EUDEBUG_CONNECT, xe_eudebug_connect_ioctl, DRM_RENDER_ALLOW),
-	DRM_IOCTL_DEF_DRV(XE_DEBUG_METADATA_CREATE, xe_debug_metadata_create_ioctl,
+	PRELIM_DRM_IOCTL_DEF_DRV(XE_EUDEBUG_CONNECT, prelim_xe_eudebug_connect_ioctl, DRM_RENDER_ALLOW),
+	PRELIM_DRM_IOCTL_DEF_DRV(XE_DEBUG_METADATA_CREATE, prelim_xe_debug_metadata_create_ioctl,
 			  DRM_RENDER_ALLOW),
-	DRM_IOCTL_DEF_DRV(XE_DEBUG_METADATA_DESTROY, xe_debug_metadata_destroy_ioctl,
+	PRELIM_DRM_IOCTL_DEF_DRV(XE_DEBUG_METADATA_DESTROY, prelim_xe_debug_metadata_destroy_ioctl,
 			  DRM_RENDER_ALLOW),
 };
 
@@ -415,7 +415,7 @@ static void xe_device_destroy(struct drm_device *dev, void *dummy)
 {
 	struct xe_device *xe = to_xe_device(dev);
 
-	xe_eudebug_fini(xe);
+	prelim_xe_eudebug_fini(xe);
 	xe_bo_dev_fini(&xe->bo_device);
 
 	if (xe->preempt_fence_wq)
@@ -499,7 +499,7 @@ struct xe_device *xe_device_create(struct pci_dev *pdev,
 	INIT_LIST_HEAD(&xe->pinned.external_vram);
 	INIT_LIST_HEAD(&xe->pinned.evicted);
 
-	xe_eudebug_init(xe);
+	prelim_xe_eudebug_init(xe);
 
 	xe->preempt_fence_wq = alloc_ordered_workqueue("xe-preempt-fence-wq",
 						       WQ_MEM_RECLAIM);
diff --git a/drivers/gpu/drm/xe/xe_device.h b/drivers/gpu/drm/xe/xe_device.h
index 7e0611c63..7713396aa 100644
--- a/drivers/gpu/drm/xe/xe_device.h
+++ b/drivers/gpu/drm/xe/xe_device.h
@@ -210,7 +210,7 @@ void xe_file_put(struct xe_file *xef);
 #define LNL_FLUSH_WORK(wrk__) \
 	flush_work(wrk__)
 
-#if IS_ENABLED(CONFIG_DRM_XE_EUDEBUG)
+#if IS_ENABLED(CONFIG_PRELIM_DRM_XE_EUDEBUG)
 static inline int xe_eudebug_needs_lock(const unsigned int cmd)
 {
 	const unsigned int xe_cmd = DRM_IOCTL_NR(cmd) - DRM_COMMAND_BASE;
@@ -221,9 +221,9 @@ static inline int xe_eudebug_needs_lock(const unsigned int cmd)
 	case DRM_XE_VM_BIND:
 	case DRM_XE_EXEC_QUEUE_CREATE:
 	case DRM_XE_EXEC_QUEUE_DESTROY:
-	case DRM_XE_EUDEBUG_CONNECT:
-	case DRM_XE_DEBUG_METADATA_CREATE:
-	case DRM_XE_DEBUG_METADATA_DESTROY:
+	case PRELIM_DRM_XE_EUDEBUG_CONNECT:
+	case PRELIM_DRM_XE_DEBUG_METADATA_CREATE:
+	case PRELIM_DRM_XE_DEBUG_METADATA_DESTROY:
 		return 1;
 	}
 
@@ -243,6 +243,6 @@ static inline void xe_eudebug_discovery_unlock(struct xe_device *xe, unsigned in
 #else
 static inline void xe_eudebug_discovery_lock(struct xe_device *xe, unsigned int cmd) { }
 static inline void xe_eudebug_discovery_unlock(struct xe_device *xe, unsigned int cmd) { }
-#endif /* CONFIG_DRM_XE_EUDEBUG */
+#endif /* CONFIG_PRELIM_DRM_XE_EUDEBUG */
 
 #endif
diff --git a/drivers/gpu/drm/xe/xe_device_types.h b/drivers/gpu/drm/xe/xe_device_types.h
index d1fbb7874..077fc7399 100644
--- a/drivers/gpu/drm/xe/xe_device_types.h
+++ b/drivers/gpu/drm/xe/xe_device_types.h
@@ -406,7 +406,7 @@ struct xe_device {
 		struct workqueue_struct *wq;
 	} sriov;
 
-#if IS_ENABLED(CONFIG_DRM_XE_EUDEBUG)
+#if IS_ENABLED(CONFIG_PRELIM_DRM_XE_EUDEBUG)
 	/** @clients: eudebug clients info */
 	struct {
 		/** @clients.lock: Protects client list */
@@ -573,7 +573,7 @@ struct xe_device {
 	u8 vm_inject_error_position;
 #endif
 
-#if IS_ENABLED(CONFIG_DRM_XE_EUDEBUG)
+#if IS_ENABLED(CONFIG_PRELIM_DRM_XE_EUDEBUG)
 	/** @debugger connection list and globals for device */
 	struct {
 		/** @lock: protects the list of connections */
@@ -718,7 +718,7 @@ struct xe_file {
 	/** @refcount: ref count of this xe file */
 	struct kref refcount;
 
-#if IS_ENABLED(CONFIG_DRM_XE_EUDEBUG)
+#if IS_ENABLED(CONFIG_PRELIM_DRM_XE_EUDEBUG)
 	struct {
 		/** @client_link: list entry in xe_device.clients.list */
 		struct list_head client_link;
diff --git a/drivers/gpu/drm/xe/xe_eudebug.h b/drivers/gpu/drm/xe/xe_eudebug.h
deleted file mode 100644
index 5f6f58ed7..000000000
--- a/drivers/gpu/drm/xe/xe_eudebug.h
+++ /dev/null
@@ -1,106 +0,0 @@
-/* SPDX-License-Identifier: MIT */
-/*
- * Copyright © 2023 Intel Corporation
- */
-
-#ifndef _XE_EUDEBUG_H_
-
-#include <linux/types.h>
-
-struct drm_device;
-struct drm_file;
-struct xe_device;
-struct xe_file;
-struct xe_gt;
-struct xe_vm;
-struct xe_vma;
-struct xe_exec_queue;
-struct xe_hw_engine;
-struct xe_user_fence;
-struct xe_debug_metadata;
-struct drm_gpuva_ops;
-struct xe_eudebug_pagefault;
-
-#if IS_ENABLED(CONFIG_DRM_XE_EUDEBUG)
-
-int xe_eudebug_connect_ioctl(struct drm_device *dev,
-			     void *data,
-			     struct drm_file *file);
-
-void xe_eudebug_init(struct xe_device *xe);
-void xe_eudebug_fini(struct xe_device *xe);
-
-void xe_eudebug_file_open(struct xe_file *xef);
-void xe_eudebug_file_close(struct xe_file *xef);
-
-void xe_eudebug_vm_create(struct xe_file *xef, struct xe_vm *vm);
-void xe_eudebug_vm_destroy(struct xe_file *xef, struct xe_vm *vm);
-
-void xe_eudebug_exec_queue_create(struct xe_file *xef, struct xe_exec_queue *q);
-void xe_eudebug_exec_queue_destroy(struct xe_file *xef, struct xe_exec_queue *q);
-
-void xe_eudebug_vm_init(struct xe_vm *vm);
-void xe_eudebug_vm_bind_start(struct xe_vm *vm);
-void xe_eudebug_vm_bind_op_add(struct xe_vm *vm, u32 op, u64 addr, u64 range,
-			       struct drm_gpuva_ops *ops);
-void xe_eudebug_vm_bind_end(struct xe_vm *vm, bool has_ufence, int err);
-
-int xe_eudebug_vm_bind_ufence(struct xe_user_fence *ufence);
-void xe_eudebug_ufence_init(struct xe_user_fence *ufence, struct xe_file *xef, struct xe_vm *vm);
-void xe_eudebug_ufence_fini(struct xe_user_fence *ufence);
-
-struct xe_eudebug *xe_eudebug_get(struct xe_file *xef);
-void xe_eudebug_put(struct xe_eudebug *d);
-
-void xe_eudebug_debug_metadata_create(struct xe_file *xef, struct xe_debug_metadata *m);
-void xe_eudebug_debug_metadata_destroy(struct xe_file *xef, struct xe_debug_metadata *m);
-
-struct xe_eudebug_pagefault *xe_eudebug_pagefault_create(struct xe_gt *gt, struct xe_vm *vm,
-							 u64 page_addr, u8 fault_type,
-							 u8 fault_level, u8 access_type);
-void xe_eudebug_pagefault_process(struct xe_gt *gt, struct xe_eudebug_pagefault *pf);
-void xe_eudebug_pagefault_destroy(struct xe_gt *gt, struct xe_vm *vm,
-				  struct xe_eudebug_pagefault *pf, bool send_event);
-
-#else
-
-static inline int xe_eudebug_connect_ioctl(struct drm_device *dev,
-					   void *data,
-					   struct drm_file *file) { return 0; }
-
-static inline void xe_eudebug_init(struct xe_device *xe) { }
-static inline void xe_eudebug_fini(struct xe_device *xe) { }
-
-static inline void xe_eudebug_file_open(struct xe_file *xef) { }
-static inline void xe_eudebug_file_close(struct xe_file *xef) { }
-
-static inline void xe_eudebug_vm_create(struct xe_file *xef, struct xe_vm *vm) { }
-static inline void xe_eudebug_vm_destroy(struct xe_file *xef, struct xe_vm *vm) { }
-
-static inline void xe_eudebug_exec_queue_create(struct xe_file *xef, struct xe_exec_queue *q) { }
-static inline void xe_eudebug_exec_queue_destroy(struct xe_file *xef, struct xe_exec_queue *q) { }
-
-static inline void xe_eudebug_vm_init(struct xe_vm *vm) { }
-static inline void xe_eudebug_vm_bind_start(struct xe_vm *vm) { }
-static inline void xe_eudebug_vm_bind_op_add(struct xe_vm *vm, u32 op, u64 addr, u64 range, struct drm_gpuva_ops *ops) { }
-static inline void xe_eudebug_vm_bind_end(struct xe_vm *vm, bool has_ufence, int err) { }
-
-static inline int xe_eudebug_vm_bind_ufence(struct xe_user_fence *ufence) { return 0; }
-static inline void xe_eudebug_ufence_init(struct xe_user_fence *ufence, struct xe_file *xef, struct xe_vm *vm) { }
-static inline void xe_eudebug_ufence_fini(struct xe_user_fence *ufence) { }
-
-static inline struct xe_eudebug *xe_eudebug_get(struct xe_file *xef) { return NULL; }
-static inline void xe_eudebug_put(struct xe_eudebug *d) { }
-
-static inline void xe_eudebug_debug_metadata_create(struct xe_file *xef, struct xe_debug_metadata *m) { }
-static inline void xe_eudebug_debug_metadata_destroy(struct xe_file *xef, struct xe_debug_metadata *m) { }
-
-static inline struct xe_eudebug_pagefault *xe_eudebug_pagefault_create(struct xe_gt *gt, struct xe_vm *vm,
-								       u64 page_addr, u8 fault_type,
-								       u8 fault_level, u8 access_type) { return NULL; }
-static inline void xe_eudebug_pagefault_process(struct xe_gt *gt, struct xe_eudebug_pagefault *pf) { }
-static inline void xe_eudebug_pagefault_destroy(struct xe_gt *gt, struct xe_vm *vm, struct xe_eudebug_pagefault *pf, bool send_event) { }
-
-#endif /* CONFIG_DRM_XE_EUDEBUG */
-
-#endif
diff --git a/drivers/gpu/drm/xe/xe_exec_queue.c b/drivers/gpu/drm/xe/xe_exec_queue.c
index 6767c57ac..b94577ff2 100644
--- a/drivers/gpu/drm/xe/xe_exec_queue.c
+++ b/drivers/gpu/drm/xe/xe_exec_queue.c
@@ -13,7 +13,7 @@
 #include <uapi/drm/xe_drm.h>
 
 #include "xe_device.h"
-#include "xe_eudebug.h"
+#include "prelim/xe_eudebug.h"
 #include "xe_gt.h"
 #include "xe_hw_engine_class_sysfs.h"
 #include "xe_hw_engine_group.h"
@@ -451,7 +451,7 @@ static int exec_queue_set_timeslice(struct xe_device *xe, struct xe_exec_queue *
 static int exec_queue_set_eudebug(struct xe_device *xe, struct xe_exec_queue *q,
 		u64 value)
 {
-	const u64 known_flags = DRM_XE_EXEC_QUEUE_EUDEBUG_FLAG_ENABLE;
+	const u64 known_flags = PRELIM_DRM_XE_EXEC_QUEUE_EUDEBUG_FLAG_ENABLE;
 
 	if (XE_IOCTL_DBG(xe, (q->class != XE_ENGINE_CLASS_RENDER &&
 					q->class != XE_ENGINE_CLASS_COMPUTE)))
@@ -460,7 +460,7 @@ static int exec_queue_set_eudebug(struct xe_device *xe, struct xe_exec_queue *q,
 	if (XE_IOCTL_DBG(xe, (value & ~known_flags)))
 		return -EINVAL;
 
-	if (XE_IOCTL_DBG(xe, !IS_ENABLED(CONFIG_DRM_XE_EUDEBUG)))
+	if (XE_IOCTL_DBG(xe, !IS_ENABLED(CONFIG_PRELIM_DRM_XE_EUDEBUG)))
 		return -EOPNOTSUPP;
 
 	if (XE_IOCTL_DBG(xe, !xe_exec_queue_is_lr(q)))
@@ -470,10 +470,10 @@ static int exec_queue_set_eudebug(struct xe_device *xe, struct xe_exec_queue *q,
 	 * property is set.
 	 */
 	if (XE_IOCTL_DBG(xe,
-				!(value & DRM_XE_EXEC_QUEUE_EUDEBUG_FLAG_ENABLE)))
+				!(value & PRELIM_DRM_XE_EXEC_QUEUE_EUDEBUG_FLAG_ENABLE)))
 		return -EINVAL;
 
-#if IS_ENABLED(CONFIG_DRM_XE_EUDEBUG)
+#if IS_ENABLED(CONFIG_PRELIM_DRM_XE_EUDEBUG)
 	if (XE_IOCTL_DBG(xe, !xe->eudebug.enable))
 		return -EPERM;
 #endif
@@ -513,7 +513,7 @@ static const xe_exec_queue_set_property_fn exec_queue_set_property_funcs[] = {
 	[DRM_XE_EXEC_QUEUE_SET_PROPERTY_PRIORITY] = exec_queue_set_priority,
 	[DRM_XE_EXEC_QUEUE_SET_PROPERTY_TIMESLICE] = exec_queue_set_timeslice,
 	[DRM_XE_EXEC_QUEUE_SET_PROPERTY_PXP_TYPE] = exec_queue_set_pxp_type,
-	[DRM_XE_EXEC_QUEUE_SET_PROPERTY_EUDEBUG] = exec_queue_set_eudebug,
+	[PRELIM_DRM_XE_EXEC_QUEUE_SET_PROPERTY_EUDEBUG] = exec_queue_set_eudebug,
 };
 
 static int exec_queue_user_ext_set_property(struct xe_device *xe,
@@ -535,7 +535,7 @@ static int exec_queue_user_ext_set_property(struct xe_device *xe,
 	    XE_IOCTL_DBG(xe, ext.property != DRM_XE_EXEC_QUEUE_SET_PROPERTY_PRIORITY &&
 			 ext.property != DRM_XE_EXEC_QUEUE_SET_PROPERTY_TIMESLICE &&
 			 ext.property != DRM_XE_EXEC_QUEUE_SET_PROPERTY_PXP_TYPE &&
-			 ext.property != DRM_XE_EXEC_QUEUE_SET_PROPERTY_EUDEBUG))
+			 ext.property != PRELIM_DRM_XE_EXEC_QUEUE_SET_PROPERTY_EUDEBUG))
 		return -EINVAL;
 
 	idx = array_index_nospec(ext.property, ARRAY_SIZE(exec_queue_set_property_funcs));
@@ -763,7 +763,7 @@ int xe_exec_queue_create_ioctl(struct drm_device *dev, void *data,
 
 	args->exec_queue_id = id;
 
-	xe_eudebug_exec_queue_create(xef, q);
+	prelim_xe_eudebug_exec_queue_create(xef, q);
 
 	return 0;
 
@@ -954,7 +954,7 @@ int xe_exec_queue_destroy_ioctl(struct drm_device *dev, void *data,
 	if (q->vm && q->hwe->hw_engine_group)
 		xe_hw_engine_group_del_exec_queue(q->hwe->hw_engine_group, q);
 
-	xe_eudebug_exec_queue_destroy(xef, q);
+	prelim_xe_eudebug_exec_queue_destroy(xef, q);
 
 	xe_exec_queue_kill(q);
 
diff --git a/drivers/gpu/drm/xe/xe_gt_pagefault.c b/drivers/gpu/drm/xe/xe_gt_pagefault.c
index 287d02775..c630077e7 100644
--- a/drivers/gpu/drm/xe/xe_gt_pagefault.c
+++ b/drivers/gpu/drm/xe/xe_gt_pagefault.c
@@ -13,7 +13,7 @@
 
 #include "abi/guc_actions_abi.h"
 #include "xe_bo.h"
-#include "xe_eudebug.h"
+#include "prelim/xe_eudebug.h"
 #include "xe_gt.h"
 #include "xe_gt_stats.h"
 #include "xe_gt_tlb_invalidation.h"
@@ -226,7 +226,7 @@ static int handle_pagefault_start(struct xe_gt *gt, struct pagefault *pf,
 	if (IS_ERR(vm))
 		return PTR_ERR(vm);
 
-	eudebug_pf = xe_eudebug_pagefault_create(gt, vm, pf->page_addr,
+	eudebug_pf = prelim_xe_eudebug_pagefault_create(gt, vm, pf->page_addr,
 			pf->fault_type, pf->fault_level,
 			pf->access_type);
 
@@ -278,7 +278,7 @@ static int handle_pagefault_start(struct xe_gt *gt, struct pagefault *pf,
 	up_write(&vm->lock);
 
 	if (destroy_eudebug_pf) {
-		xe_eudebug_pagefault_destroy(gt, vm, eudebug_pf, false);
+		prelim_xe_eudebug_pagefault_destroy(gt, vm, eudebug_pf, false);
 		*eudebug_pf_out = NULL;
 	} else {
 		*eudebug_pf_out = eudebug_pf;
@@ -303,13 +303,13 @@ static void handle_pagefault_end(struct xe_gt *gt, struct xe_vm *vm,
 	if (!eudebug_pf)
 		return;
 
-	xe_eudebug_pagefault_process(gt, eudebug_pf);
+	prelim_xe_eudebug_pagefault_process(gt, eudebug_pf);
 
 	/*
 	 * TODO: Remove VMA added to handle eudebug pagefault
 	 */
 
-	xe_eudebug_pagefault_destroy(gt, vm, eudebug_pf, true);
+	prelim_xe_eudebug_pagefault_destroy(gt, vm, eudebug_pf, true);
 
 	xe_vm_put(vm);
 }
diff --git a/drivers/gpu/drm/xe/xe_hw_engine.c b/drivers/gpu/drm/xe/xe_hw_engine.c
index b03844546..00be23ee1 100644
--- a/drivers/gpu/drm/xe/xe_hw_engine.c
+++ b/drivers/gpu/drm/xe/xe_hw_engine.c
@@ -18,7 +18,7 @@
 #include "xe_assert.h"
 #include "xe_bo.h"
 #include "xe_device.h"
-#include "xe_eudebug.h"
+#include "prelim/xe_eudebug.h"
 #include "xe_execlist.h"
 #include "xe_force_wake.h"
 #include "xe_gsc.h"
diff --git a/drivers/gpu/drm/xe/xe_sync.c b/drivers/gpu/drm/xe/xe_sync.c
index 30c171b97..fbd31970d 100644
--- a/drivers/gpu/drm/xe/xe_sync.c
+++ b/drivers/gpu/drm/xe/xe_sync.c
@@ -15,7 +15,7 @@
 #include <uapi/drm/xe_drm.h>
 
 #include "xe_device_types.h"
-#include "xe_eudebug.h"
+#include "prelim/xe_eudebug.h"
 #include "xe_exec_queue.h"
 #include "xe_macros.h"
 #include "xe_sched_job_types.h"
@@ -27,7 +27,7 @@ static void user_fence_destroy(struct kref *kref)
 
 	mmdrop(ufence->mm);
 
-	xe_eudebug_ufence_fini(ufence);
+	prelim_xe_eudebug_ufence_fini(ufence);
 
 	kfree(ufence);
 }
@@ -66,7 +66,7 @@ static struct xe_user_fence *user_fence_create(struct xe_device *xe,
 	ufence->mm = current->mm;
 	mmgrab(ufence->mm);
 
-	xe_eudebug_ufence_init(ufence, xef, vm);
+	prelim_xe_eudebug_ufence_init(ufence, xef, vm);
 
 	return ufence;
 }
@@ -97,10 +97,10 @@ static void user_fence_worker(struct work_struct *w)
 	 * Wake up waiters only after updating the ufence state, allowing the UMD
 	 * to safely reuse the same ufence without encountering -EBUSY errors.
 	 */
-	WRITE_ONiCE(ufence->signalled, 1);
+	WRITE_ONCE(ufence->signalled, 1);
 
 	/* Lets see if debugger wants to track this */
-	ret = xe_eudebug_vm_bind_ufence(ufence);
+	ret = prelim_xe_eudebug_vm_bind_ufence(ufence);
 	if (ret)
 		xe_sync_ufence_signal(ufence);
 
diff --git a/drivers/gpu/drm/xe/xe_sync_types.h b/drivers/gpu/drm/xe/xe_sync_types.h
index dcd3165e6..63807cfe5 100644
--- a/drivers/gpu/drm/xe/xe_sync_types.h
+++ b/drivers/gpu/drm/xe/xe_sync_types.h
@@ -21,7 +21,7 @@ struct xe_user_fence {
 	u64 value;
 	int signalled;
 
-#if IS_ENABLED(CONFIG_DRM_XE_EUDEBUG)
+#if IS_ENABLED(CONFIG_PRELIM_DRM_XE_EUDEBUG)
 	struct {
 		spinlock_t lock;
 		struct xe_eudebug *debugger;
diff --git a/drivers/gpu/drm/xe/xe_vm.c b/drivers/gpu/drm/xe/xe_vm.c
index 60dd37378..f6bccd363 100644
--- a/drivers/gpu/drm/xe/xe_vm.c
+++ b/drivers/gpu/drm/xe/xe_vm.c
@@ -24,10 +24,10 @@
 #include "regs/xe_gtt_defs.h"
 #include "xe_assert.h"
 #include "xe_bo.h"
-#include "xe_debug_metadata.h"
+#include "prelim/xe_debug_metadata.h"
 #include "xe_device.h"
 #include "xe_drm_client.h"
-#include "xe_eudebug.h"
+#include "prelim/xe_eudebug.h"
 #include "xe_exec_queue.h"
 #include "xe_gt_pagefault.h"
 #include "xe_gt_tlb_invalidation.h"
@@ -1180,7 +1180,7 @@ static struct xe_vma *xe_vma_create(struct xe_vm *vm,
 			vma->gpuva.gem.obj = &bo->ttm.base;
 	}
 
-#if IS_ENABLED(CONFIG_DRM_XE_EUDEBUG)
+#if IS_ENABLED(CONFIG_PRELIM_DRM_XE_EUDEBUG)
 	INIT_LIST_HEAD(&vma->eudebug.metadata.list);
 #endif
 	INIT_LIST_HEAD(&vma->combined_links.rebind);
@@ -1676,7 +1676,7 @@ struct xe_vm *xe_vm_create(struct xe_device *xe, u32 flags)
 	for_each_tile(tile, xe, id)
 		xe_range_fence_tree_init(&vm->rftree[id]);
 
-	xe_eudebug_vm_init(vm);
+	prelim_xe_eudebug_vm_init(vm);
 
 	vm->pt_ops = &xelp_pt_ops;
 
@@ -1952,7 +1952,7 @@ static void vm_destroy_work_func(struct work_struct *w)
 	struct xe_tile *tile;
 	u8 id;
 
-	xe_eudebug_vm_bind_end(vm, 0, -ENOENT);
+	prelim_xe_eudebug_vm_bind_end(vm, 0, -ENOENT);
 
 	/* xe_vm_close_and_put was not called? */
 	xe_assert(xe, !vm->size);
@@ -2108,7 +2108,7 @@ int xe_vm_create_ioctl(struct drm_device *dev, void *data,
 
 	args->vm_id = id;
 
-	xe_eudebug_vm_create(xef, vm);
+	prelim_xe_eudebug_vm_create(xef, vm);
 
 	return 0;
 
@@ -2142,7 +2142,7 @@ int xe_vm_destroy_ioctl(struct drm_device *dev, void *data,
 	mutex_unlock(&xef->vm.lock);
 
 	if (!err) {
-		xe_eudebug_vm_destroy(xef, vm);
+		prelim_xe_eudebug_vm_destroy(xef, vm);
 		xe_vm_close_and_put(vm);
 	}
 
@@ -2287,7 +2287,7 @@ vm_bind_ioctl_ops_create(struct xe_vm *vm, struct xe_bo *bo,
 				DRM_XE_VM_BIND_FLAG_CPU_ADDR_MIRROR;
 			op->map.dumpable = flags & DRM_XE_VM_BIND_FLAG_DUMPABLE;
 			op->map.pat_index = pat_index;
-#if IS_ENABLED(CONFIG_DRM_XE_EUDEBUG)
+#if IS_ENABLED(CONFIG_PRELIM_DRM_XE_EUDEBUG)
 			INIT_LIST_HEAD(&op->map.eudebug.metadata.list);
 #endif
 		} else if (__op->op == DRM_GPUVA_OP_PREFETCH) {
@@ -2900,7 +2900,7 @@ typedef int (*xe_vm_bind_op_user_extension_fn)(struct xe_device *xe,
 					       u32 operation, u64 extension);
 
 static const xe_vm_bind_op_user_extension_fn vm_bind_op_extension_funcs[] = {
-	[XE_VM_BIND_OP_EXTENSIONS_ATTACH_DEBUG] = vm_bind_op_ext_attach_debug,
+	[PRELIM_XE_VM_BIND_OP_EXTENSIONS_ATTACH_DEBUG] = vm_bind_op_ext_attach_debug,
 };
 
 #define MAX_USER_EXTENSIONS	16
@@ -3083,7 +3083,7 @@ static void vm_bind_ioctl_ops_fini(struct xe_vm *vm, struct xe_vma_ops *vops,
 				       fence);
 	}
 
-	xe_eudebug_vm_bind_end(vm, ufence, 0);
+	prelim_xe_eudebug_vm_bind_end(vm, ufence, 0);
 	
 	if (ufence)
 		xe_sync_ufence_put(ufence);
@@ -3485,7 +3485,7 @@ int xe_vm_bind_ioctl(struct drm_device *dev, void *data, struct drm_file *file)
 		}
 	}
 
-	xe_eudebug_vm_bind_start(vm);
+	prelim_xe_eudebug_vm_bind_start(vm);
 
 	syncs_user = u64_to_user_ptr(args->syncs);
 	for (num_syncs = 0; num_syncs < args->num_syncs; num_syncs++) {
@@ -3541,7 +3541,7 @@ int xe_vm_bind_ioctl(struct drm_device *dev, void *data, struct drm_file *file)
 		if (err)
 			goto unwind_ops;
 
-		xe_eudebug_vm_bind_op_add(vm, op, addr, range, ops[i]);
+		prelim_xe_eudebug_vm_bind_op_add(vm, op, addr, range, ops[i]);
 
 #ifdef TEST_VM_OPS_ERROR
 		if (flags & FORCE_OP_ERROR) {
@@ -3571,7 +3571,7 @@ int xe_vm_bind_ioctl(struct drm_device *dev, void *data, struct drm_file *file)
 
 unwind_ops:
 	if (err && err != -ENODATA) {
-		xe_eudebug_vm_bind_end(vm, num_ufence > 0, err);
+		prelim_xe_eudebug_vm_bind_end(vm, num_ufence > 0, err);
 		vm_bind_ioctl_ops_unwind(vm, ops, args->num_binds);
 	}
 	xe_vma_ops_fini(&vops);
diff --git a/drivers/gpu/drm/xe/xe_vm_types.h b/drivers/gpu/drm/xe/xe_vm_types.h
index a0d3d5b16..e34a8ece3 100644
--- a/drivers/gpu/drm/xe/xe_vm_types.h
+++ b/drivers/gpu/drm/xe/xe_vm_types.h
@@ -77,7 +77,7 @@ struct xe_userptr {
 #endif
 };
 
-#if IS_ENABLED(CONFIG_DRM_XE_EUDEBUG)
+#if IS_ENABLED(CONFIG_PRELIM_DRM_XE_EUDEBUG)
 struct xe_eudebug_vma_metadata {
 	struct list_head list;
 };
@@ -328,7 +328,7 @@ struct xe_vm {
 	/** @xef: XE file handle for tracking this VM's drm client */
 	struct xe_file *xef;
 
-#if IS_ENABLED(CONFIG_DRM_XE_EUDEBUG)
+#if IS_ENABLED(CONFIG_PRELIM_DRM_XE_EUDEBUG)
 	struct {
 		/** @lock: Lock for eudebug_bind members */
 		spinlock_t lock;
diff --git a/include/uapi/drm/xe_drm.h b/include/uapi/drm/xe_drm.h
index 27a86e118..1717a3187 100644
--- a/include/uapi/drm/xe_drm.h
+++ b/include/uapi/drm/xe_drm.h
@@ -102,9 +102,6 @@ extern "C" {
 #define DRM_XE_EXEC			0x09
 #define DRM_XE_WAIT_USER_FENCE		0x0a
 #define DRM_XE_OBSERVATION		0x0b
-#define DRM_XE_EUDEBUG_CONNECT		0x0c
-#define DRM_XE_DEBUG_METADATA_CREATE	0x0d
-#define DRM_XE_DEBUG_METADATA_DESTROY	0x0e
 /* Must be kept compact -- no holes */
 
 #define DRM_IOCTL_XE_DEVICE_QUERY		DRM_IOWR(DRM_COMMAND_BASE + DRM_XE_DEVICE_QUERY, struct drm_xe_device_query)
@@ -119,9 +116,6 @@ extern "C" {
 #define DRM_IOCTL_XE_EXEC			DRM_IOW(DRM_COMMAND_BASE + DRM_XE_EXEC, struct drm_xe_exec)
 #define DRM_IOCTL_XE_WAIT_USER_FENCE		DRM_IOWR(DRM_COMMAND_BASE + DRM_XE_WAIT_USER_FENCE, struct drm_xe_wait_user_fence)
 #define DRM_IOCTL_XE_OBSERVATION		DRM_IOW(DRM_COMMAND_BASE + DRM_XE_OBSERVATION, struct drm_xe_observation_param)
-#define DRM_IOCTL_XE_EUDEBUG_CONNECT		DRM_IOWR(DRM_COMMAND_BASE + DRM_XE_EUDEBUG_CONNECT, struct drm_xe_eudebug_connect)
-#define DRM_IOCTL_XE_DEBUG_METADATA_CREATE	 DRM_IOWR(DRM_COMMAND_BASE + DRM_XE_DEBUG_METADATA_CREATE, struct drm_xe_debug_metadata_create)
-#define DRM_IOCTL_XE_DEBUG_METADATA_DESTROY	 DRM_IOW(DRM_COMMAND_BASE + DRM_XE_DEBUG_METADATA_DESTROY, struct drm_xe_debug_metadata_destroy)
 
 /**
  * DOC: Xe IOCTL Extensions
@@ -972,23 +966,6 @@ struct drm_xe_vm_destroy {
 	__u64 reserved[2];
 };
 
-struct drm_xe_vm_bind_op_ext_attach_debug {
-	/** @base: base user extension */
-	struct drm_xe_user_extension base;
-
-	/** @id: Debug object id from create metadata */
-	__u64 metadata_id;
-
-	/** @flags: Flags */
-	__u64 flags;
-
-	/** @cookie: Cookie */
-	__u64 cookie;
-
-	/** @reserved: Reserved */
-	__u64 reserved;
-};
-
 /**
  * struct drm_xe_vm_bind_op - run bind operations
  *
@@ -1023,7 +1000,6 @@ struct drm_xe_vm_bind_op_ext_attach_debug {
  *    handle MBZ, and the BO offset MBZ.
  */
 struct drm_xe_vm_bind_op {
-#define XE_VM_BIND_OP_EXTENSIONS_ATTACH_DEBUG 0
 	/** @extensions: Pointer to the first extension struct, if any */
 	__u64 extensions;
 
@@ -1272,8 +1248,6 @@ struct drm_xe_exec_queue_create {
 #define   DRM_XE_EXEC_QUEUE_SET_PROPERTY_PRIORITY		0
 #define   DRM_XE_EXEC_QUEUE_SET_PROPERTY_TIMESLICE		1
 #define   DRM_XE_EXEC_QUEUE_SET_PROPERTY_PXP_TYPE		2
-#define   DRM_XE_EXEC_QUEUE_SET_PROPERTY_EUDEBUG                2
-#define   DRM_XE_EXEC_QUEUE_EUDEBUG_FLAG_ENABLE                 (1 << 0)
 
 	/** @extensions: Pointer to the first extension struct, if any */
 	__u64 extensions;
@@ -1987,72 +1961,6 @@ struct drm_xe_query_eu_stall {
 	__u64 sampling_rates[];
 };
 
-/*
- * Debugger ABI (ioctl and events) Version History:
- * 0 - No debugger available
- * 1 - Initial version
- */
-#define DRM_XE_EUDEBUG_VERSION 1
-
-struct drm_xe_eudebug_connect {
-	/** @extensions: Pointer to the first extension struct, if any */
-	__u64 extensions;
-
-	__u64 pid; /* input: Target process ID */
-	__u32 flags; /* MBZ */
-
-	__u32 version; /* output: current ABI (ioctl / events) version */
-};
-
-/*
- * struct drm_xe_debug_metadata_create - Create debug metadata
- *
- * Add a region of user memory to be marked as debug metadata.
- * When the debugger attaches, the metadata regions will be delivered
- * for debugger. Debugger can then map these regions to help decode
- * the program state.
- *
- * Returns handle to created metadata entry.
- */
-struct drm_xe_debug_metadata_create {
-	/** @extensions: Pointer to the first extension struct, if any */
-	__u64 extensions;
-
-#define DRM_XE_DEBUG_METADATA_ELF_BINARY     0
-#define DRM_XE_DEBUG_METADATA_PROGRAM_MODULE 1
-#define WORK_IN_PROGRESS_DRM_XE_DEBUG_METADATA_MODULE_AREA 2
-#define WORK_IN_PROGRESS_DRM_XE_DEBUG_METADATA_SBA_AREA 3
-#define WORK_IN_PROGRESS_DRM_XE_DEBUG_METADATA_SIP_AREA 4
-#define WORK_IN_PROGRESS_DRM_XE_DEBUG_METADATA_NUM (1 + \
-	  WORK_IN_PROGRESS_DRM_XE_DEBUG_METADATA_SIP_AREA)
-
-	/** @type: Type of metadata */
-	__u64 type;
-
-	/** @user_addr: pointer to start of the metadata */
-	__u64 user_addr;
-
-	/** @len: length, in bytes of the medata */
-	__u64 len;
-
-	/** @metadata_id: created metadata handle (out) */
-	__u32 metadata_id;
-};
-
-/**
- * struct drm_xe_debug_metadata_destroy - Destroy debug metadata
- *
- * Destroy debug metadata.
- */
-struct drm_xe_debug_metadata_destroy {
-	/** @extensions: Pointer to the first extension struct, if any */
-	__u64 extensions;
-
-	/** @metadata_id: metadata handle to destroy */
-	__u32 metadata_id;
-};
-
-#include "xe_drm_eudebug.h"
 #include "xe_drm_prelim.h"
 
 #if defined(__cplusplus)
diff --git a/include/uapi/drm/xe_drm_eudebug.h b/include/uapi/drm/xe_drm_eudebug.h
deleted file mode 100644
index e43576c7b..000000000
--- a/include/uapi/drm/xe_drm_eudebug.h
+++ /dev/null
@@ -1,256 +0,0 @@
-/* SPDX-License-Identifier: MIT */
-/*
- * Copyright © 2023 Intel Corporation
- */
-
-#ifndef _UAPI_XE_DRM_EUDEBUG_H_
-#define _UAPI_XE_DRM_EUDEBUG_H_
-
-#if defined(__cplusplus)
-extern "C" {
-#endif
-
-/**
- * Do a eudebug event read for a debugger connection.
- *
- * This ioctl is available in debug version 1.
- */
-#define DRM_XE_EUDEBUG_IOCTL_READ_EVENT		_IO('j', 0x0)
-#define DRM_XE_EUDEBUG_IOCTL_EU_CONTROL		_IOWR('j', 0x2, struct drm_xe_eudebug_eu_control)
-#define DRM_XE_EUDEBUG_IOCTL_ACK_EVENT		_IOW('j', 0x4, struct drm_xe_eudebug_ack_event)
-#define DRM_XE_EUDEBUG_IOCTL_VM_OPEN		_IOW('j', 0x1, struct drm_xe_eudebug_vm_open)
-#define DRM_XE_EUDEBUG_IOCTL_READ_METADATA	_IOWR('j', 0x3, struct drm_xe_eudebug_read_metadata)
-
-/* XXX: Document events to match their internal counterparts when moved to xe_drm.h */
-struct drm_xe_eudebug_event {
-	__u32 len;
-
-	__u16 type;
-#define DRM_XE_EUDEBUG_EVENT_NONE		0
-#define DRM_XE_EUDEBUG_EVENT_READ		1
-#define DRM_XE_EUDEBUG_EVENT_OPEN		2
-#define DRM_XE_EUDEBUG_EVENT_VM			3
-#define DRM_XE_EUDEBUG_EVENT_EXEC_QUEUE		4
-#define DRM_XE_EUDEBUG_EVENT_EXEC_QUEUE_PLACEMENTS 5
-#define DRM_XE_EUDEBUG_EVENT_EU_ATTENTION	6
-#define DRM_XE_EUDEBUG_EVENT_VM_BIND		7
-#define DRM_XE_EUDEBUG_EVENT_VM_BIND_OP		8
-#define DRM_XE_EUDEBUG_EVENT_VM_BIND_UFENCE	9
-#define DRM_XE_EUDEBUG_EVENT_METADATA		10
-#define DRM_XE_EUDEBUG_EVENT_VM_BIND_OP_METADATA 11
-#define DRM_XE_EUDEBUG_EVENT_PAGEFAULT		12
-
-	__u16 flags;
-#define DRM_XE_EUDEBUG_EVENT_CREATE		(1 << 0)
-#define DRM_XE_EUDEBUG_EVENT_DESTROY		(1 << 1)
-#define DRM_XE_EUDEBUG_EVENT_STATE_CHANGE	(1 << 2)
-#define DRM_XE_EUDEBUG_EVENT_NEED_ACK		(1 << 3)
-
-	__u64 seqno;
-	__u64 reserved;
-};
-
-struct drm_xe_eudebug_event_client {
-	struct drm_xe_eudebug_event base;
-
-	__u64 client_handle; /* This is unique per debug connection */
-};
-
-struct drm_xe_eudebug_event_vm {
-	struct drm_xe_eudebug_event base;
-
-	__u64 client_handle;
-	__u64 vm_handle;
-};
-
-struct drm_xe_eudebug_event_exec_queue {
-	struct drm_xe_eudebug_event base;
-
-	__u64 client_handle;
-	__u64 vm_handle;
-	__u64 exec_queue_handle;
-	__u32 engine_class;
-	__u32 width;
-	__u64 lrc_handle[];
-};
-
-struct drm_xe_eudebug_event_exec_queue_placements {
-	struct drm_xe_eudebug_event base;
-
-	__u64 client_handle;
-	__u64 vm_handle;
-	__u64 exec_queue_handle;
-	__u64 lrc_handle;
-	__u32 num_placements;
-	__u32 pad;
-	/**
-	 * @instances: user pointer to num_placements sized array of struct
-	 * drm_xe_engine_class_instance
-	 */
-	__u64 instances[];
-};
-
-struct drm_xe_eudebug_event_eu_attention {
-	struct drm_xe_eudebug_event base;
-
-	__u64 client_handle;
-	__u64 exec_queue_handle;
-	__u64 lrc_handle;
-	__u32 flags;
-	__u32 bitmask_size;
-	__u8 bitmask[];
-};
-
-struct drm_xe_eudebug_eu_control {
-	__u64 client_handle;
-
-#define DRM_XE_EUDEBUG_EU_CONTROL_CMD_INTERRUPT_ALL	0
-#define DRM_XE_EUDEBUG_EU_CONTROL_CMD_STOPPED		1
-#define DRM_XE_EUDEBUG_EU_CONTROL_CMD_RESUME		2
-	__u32 cmd;
-	__u32 flags;
-
-	__u64 seqno;
-
-	__u64 exec_queue_handle;
-	__u64 lrc_handle;
-	__u32 reserved;
-	__u32 bitmask_size;
-	__u64 bitmask_ptr;
-};
-
-/*
- *  When client (debuggee) does vm_bind_ioctl() following event
- *  sequence will be created (for the debugger):
- *
- *  ┌───────────────────────┐
- *  │  EVENT_VM_BIND        ├───────┬─┬─┐
- *  └───────────────────────┘       │ │ │
- *      ┌───────────────────────┐   │ │ │
- *      │ EVENT_VM_BIND_OP #1   ├───┘ │ │
- *      └───────────────────────┘     │ │
- *                 ...                │ │
- *      ┌───────────────────────┐     │ │
- *      │ EVENT_VM_BIND_OP #n   ├─────┘ │
- *      └───────────────────────┘       │
- *                                      │
- *      ┌───────────────────────┐       │
- *      │ EVENT_UFENCE          ├───────┘
- *      └───────────────────────┘
- *
- * All the events below VM_BIND will reference the VM_BIND
- * they associate with, by field .vm_bind_ref_seqno.
- * event_ufence will only be included if the client did
- * attach sync of type UFENCE into its vm_bind_ioctl().
- *
- * When EVENT_UFENCE is sent by the driver, all the OPs of
- * the original VM_BIND are completed and the [addr,range]
- * contained in them are present and modifiable through the
- * vm accessors. Accessing [addr, range] before related ufence
- * event will lead to undefined results as the actual bind
- * operations are async and the backing storage might not
- * be there on a moment of receiving the event.
- *
- * Client's UFENCE sync will be held by the driver: client's
- * drm_xe_wait_ufence will not complete and the value of the ufence
- * won't appear until ufence is acked by the debugger process calling
- * DRM_XE_EUDEBUG_IOCTL_ACK_EVENT with the event_ufence.base.seqno.
- * This will signal the fence, .value will update and the wait will
- * complete allowing the client to continue.
- *
- */
-
-struct drm_xe_eudebug_event_vm_bind {
-	struct drm_xe_eudebug_event base;
-
-	__u64 client_handle;
-	__u64 vm_handle;
-
-	__u32 flags;
-#define DRM_XE_EUDEBUG_EVENT_VM_BIND_FLAG_UFENCE (1 << 0)
-
-	__u32 num_binds;
-};
-
-struct drm_xe_eudebug_event_vm_bind_op {
-	struct drm_xe_eudebug_event base;
-	__u64 vm_bind_ref_seqno; /* *_event_vm_bind.base.seqno */
-	__u64 num_extensions;
-
-	__u64 addr; /* XXX: Zero for unmap all? */
-	__u64 range; /* XXX: Zero for unmap all? */
-};
-
-struct drm_xe_eudebug_event_vm_bind_ufence {
-	struct drm_xe_eudebug_event base;
-	__u64 vm_bind_ref_seqno; /* *_event_vm_bind.base.seqno */
-};
-
-struct drm_xe_eudebug_ack_event {
-	__u32 type;
-	__u32 flags; /* MBZ */
-	__u64 seqno;
-};
-
-struct drm_xe_eudebug_vm_open {
-	/** @extensions: Pointer to the first extension struct, if any */
-	__u64 extensions;
-
-	/** @client_handle: id of client */
-	__u64 client_handle;
-
-	/** @vm_handle: id of vm */
-	__u64 vm_handle;
-
-	/** @flags: flags */
-	__u64 flags;
-
-#define DRM_XE_EUDEBUG_VM_SYNC_MAX_TIMEOUT_NSECS (10ULL * NSEC_PER_SEC)
-	/** @timeout_ns: Timeout value in nanoseconds operations (fsync) */
-	__u64 timeout_ns;
-};
-
-struct drm_xe_eudebug_read_metadata {
-	__u64 client_handle;
-	__u64 metadata_handle;
-	__u32 flags;
-	__u32 reserved;
-	__u64 ptr;
-	__u64 size;
-};
-
-struct drm_xe_eudebug_event_metadata {
-	struct drm_xe_eudebug_event base;
-
-	__u64 client_handle;
-	__u64 metadata_handle;
-	/* XXX: Refer to xe_drm.h for fields */
-	__u64 type;
-	__u64 len;
-};
-
-struct drm_xe_eudebug_event_vm_bind_op_metadata {
-	struct drm_xe_eudebug_event base;
-	__u64 vm_bind_op_ref_seqno; /* *_event_vm_bind_op.base.seqno */
-
-	__u64 metadata_handle;
-	__u64 metadata_cookie;
-};
-
-struct drm_xe_eudebug_event_pagefault {
-	struct drm_xe_eudebug_event base;
-
-	__u64 client_handle;
-	__u64 exec_queue_handle;
-	__u64 lrc_handle;
-	__u32 flags;
-	__u32 bitmask_size;
-	__u64 pagefault_address;
-	__u8 bitmask[];
-};
-
-#if defined(__cplusplus)
-}
-#endif
-
-#endif
diff --git a/include/uapi/drm/xe_drm_prelim.h b/include/uapi/drm/xe_drm_prelim.h
index 9c86f5969..d5f794b0f 100644
--- a/include/uapi/drm/xe_drm_prelim.h
+++ b/include/uapi/drm/xe_drm_prelim.h
@@ -70,4 +70,344 @@
  * components. Please add an unreserved ioctl number here to reserve that
  * number.
  */
+/* SPDX-License-Identifier: MIT */
+/*
+ * Copyright © 2023 Intel Corporation
+ */
+
+#define PRELIM_DRM_XE_EUDEBUG_CONNECT 0x5f
+#define PRELIM_DRM_XE_DEBUG_METADATA_CREATE 0x5e
+#define PRELIM_DRM_XE_DEBUG_METADATA_DESTROY 0x5d
+
+#define PRELIM_DRM_IOCTL_XE_EUDEBUG_CONNECT		DRM_IOWR(DRM_COMMAND_BASE + PRELIM_DRM_XE_EUDEBUG_CONNECT, struct prelim_drm_xe_eudebug_connect)
+#define PRELIM_DRM_IOCTL_XE_DEBUG_METADATA_CREATE	 DRM_IOWR(DRM_COMMAND_BASE + PRELIM_DRM_XE_DEBUG_METADATA_CREATE, struct prelim_drm_xe_debug_metadata_create)
+#define PRELIM_DRM_IOCTL_XE_DEBUG_METADATA_DESTROY	 DRM_IOW(DRM_COMMAND_BASE + PRELIM_DRM_XE_DEBUG_METADATA_DESTROY, struct prelim_drm_xe_debug_metadata_destroy)
+
+struct prelim_drm_xe_vm_bind_op_ext_attach_debug {
+	/** @base: base user extension */
+	struct drm_xe_user_extension base;
+
+	/** @id: Debug object id from create metadata */
+	__u64 metadata_id;
+
+	/** @flags: Flags */
+	__u64 flags;
+
+	/** @cookie: Cookie */
+	__u64 cookie;
+
+	/** @reserved: Reserved */
+	__u64 reserved;
+};
+
+#define PRELIM_XE_VM_BIND_OP_EXTENSIONS_ATTACH_DEBUG 0
+
+#define   PRELIM_DRM_XE_EXEC_QUEUE_SET_PROPERTY_EUDEBUG		2
+#define     PRELIM_DRM_XE_EXEC_QUEUE_EUDEBUG_FLAG_ENABLE		(1 << 0)
+
+/*
+ * Debugger ABI (ioctl and events) Version History:
+ * 0 - No debugger available
+ * 1 - Initial version
+ */
+#define PRELIM_DRM_XE_EUDEBUG_VERSION 1
+
+struct prelim_drm_xe_eudebug_connect {
+	/** @extensions: Pointer to the first extension struct, if any */
+	__u64 extensions;
+
+	__u64 pid; /* input: Target process ID */
+	__u32 flags; /* MBZ */
+
+	__u32 version; /* output: current ABI (ioctl / events) version */
+};
+
+/*
+ * struct drm_xe_debug_metadata_create - Create debug metadata
+ *
+ * Add a region of user memory to be marked as debug metadata.
+ * When the debugger attaches, the metadata regions will be delivered
+ * for debugger. Debugger can then map these regions to help decode
+ * the program state.
+ *
+ * Returns handle to created metadata entry.
+ */
+struct prelim_drm_xe_debug_metadata_create {
+	/** @extensions: Pointer to the first extension struct, if any */
+	__u64 extensions;
+
+#define PRELIM_DRM_XE_DEBUG_METADATA_ELF_BINARY     0
+#define PRELIM_DRM_XE_DEBUG_METADATA_PROGRAM_MODULE 1
+#define PRELIM_WORK_IN_PROGRESS_DRM_XE_DEBUG_METADATA_MODULE_AREA 2
+#define PRELIM_WORK_IN_PROGRESS_DRM_XE_DEBUG_METADATA_SBA_AREA 3
+#define PRELIM_WORK_IN_PROGRESS_DRM_XE_DEBUG_METADATA_SIP_AREA 4
+#define PRELIM_WORK_IN_PROGRESS_DRM_XE_DEBUG_METADATA_NUM (1 + \
+	  PRELIM_WORK_IN_PROGRESS_DRM_XE_DEBUG_METADATA_SIP_AREA)
+
+	/** @type: Type of metadata */
+	__u64 type;
+
+	/** @user_addr: pointer to start of the metadata */
+	__u64 user_addr;
+
+	/** @len: length, in bytes of the medata */
+	__u64 len;
+
+	/** @metadata_id: created metadata handle (out) */
+	__u32 metadata_id;
+};
+
+/**
+ * struct drm_xe_debug_metadata_destroy - Destroy debug metadata
+ *
+ * Destroy debug metadata.
+ */
+struct prelim_drm_xe_debug_metadata_destroy {
+	/** @extensions: Pointer to the first extension struct, if any */
+	__u64 extensions;
+
+	/** @metadata_id: metadata handle to destroy */
+	__u32 metadata_id;
+};
+
+/**
+ * Do a eudebug event read for a debugger connection.
+ *
+ * This ioctl is available in debug version 1.
+ */
+#define PRELIM_DRM_XE_EUDEBUG_IOCTL_READ_EVENT		_IO('j', 0x0)
+#define PRELIM_DRM_XE_EUDEBUG_IOCTL_EU_CONTROL		_IOWR('j', 0x2, struct prelim_drm_xe_eudebug_eu_control)
+#define PRELIM_DRM_XE_EUDEBUG_IOCTL_ACK_EVENT		_IOW('j', 0x4, struct prelim_drm_xe_eudebug_ack_event)
+#define PRELIM_DRM_XE_EUDEBUG_IOCTL_VM_OPEN		_IOW('j', 0x1, struct prelim_drm_xe_eudebug_vm_open)
+#define PRELIM_DRM_XE_EUDEBUG_IOCTL_READ_METADATA	_IOWR('j', 0x3, struct prelim_drm_xe_eudebug_read_metadata)
+
+/* XXX: Document events to match their internal counterparts when moved to xe_drm.h */
+struct prelim_drm_xe_eudebug_event {
+	__u32 len;
+
+	__u16 type;
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_NONE		0
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_READ		1
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_OPEN		2
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_VM			3
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_EXEC_QUEUE		4
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_EXEC_QUEUE_PLACEMENTS 5
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_EU_ATTENTION	6
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_VM_BIND		7
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_VM_BIND_OP		8
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_VM_BIND_UFENCE	9
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_METADATA		10
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_VM_BIND_OP_METADATA 11
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_PAGEFAULT		12
+
+	__u16 flags;
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_CREATE		(1 << 0)
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_DESTROY		(1 << 1)
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_STATE_CHANGE	(1 << 2)
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_NEED_ACK		(1 << 3)
+
+	__u64 seqno;
+	__u64 reserved;
+};
+
+struct prelim_drm_xe_eudebug_event_client {
+	struct prelim_drm_xe_eudebug_event base;
+
+	__u64 client_handle; /* This is unique per debug connection */
+};
+
+struct prelim_drm_xe_eudebug_event_vm {
+	struct prelim_drm_xe_eudebug_event base;
+
+	__u64 client_handle;
+	__u64 vm_handle;
+};
+
+struct prelim_drm_xe_eudebug_event_exec_queue {
+	struct prelim_drm_xe_eudebug_event base;
+
+	__u64 client_handle;
+	__u64 vm_handle;
+	__u64 exec_queue_handle;
+	__u32 engine_class;
+	__u32 width;
+	__u64 lrc_handle[];
+};
+
+struct prelim_drm_xe_eudebug_event_exec_queue_placements {
+	struct prelim_drm_xe_eudebug_event base;
+
+	__u64 client_handle;
+	__u64 vm_handle;
+	__u64 exec_queue_handle;
+	__u64 lrc_handle;
+	__u32 num_placements;
+	__u32 pad;
+	/**
+	 * @instances: user pointer to num_placements sized array of struct
+	 * drm_xe_engine_class_instance
+	 */
+	__u64 instances[];
+};
+
+struct prelim_drm_xe_eudebug_event_eu_attention {
+	struct prelim_drm_xe_eudebug_event base;
+
+	__u64 client_handle;
+	__u64 exec_queue_handle;
+	__u64 lrc_handle;
+	__u32 flags;
+	__u32 bitmask_size;
+	__u8 bitmask[];
+};
+
+struct prelim_drm_xe_eudebug_eu_control {
+	__u64 client_handle;
+
+#define PRELIM_DRM_XE_EUDEBUG_EU_CONTROL_CMD_INTERRUPT_ALL	0
+#define PRELIM_DRM_XE_EUDEBUG_EU_CONTROL_CMD_STOPPED		1
+#define PRELIM_DRM_XE_EUDEBUG_EU_CONTROL_CMD_RESUME		2
+
+	__u32 cmd;
+	__u32 flags;
+
+	__u64 seqno;
+
+	__u64 exec_queue_handle;
+	__u64 lrc_handle;
+	__u32 reserved;
+	__u32 bitmask_size;
+	__u64 bitmask_ptr;
+};
+
+/*
+ *  When client (debuggee) does vm_bind_ioctl() following event
+ *  sequence will be created (for the debugger):
+ *
+ *  ┌───────────────────────┐
+ *  │  EVENT_VM_BIND        ├───────┬─┬─┐
+ *  └───────────────────────┘       │ │ │
+ *      ┌───────────────────────┐   │ │ │
+ *      │ EVENT_VM_BIND_OP #1   ├───┘ │ │
+ *      └───────────────────────┘     │ │
+ *                 ...                │ │
+ *      ┌───────────────────────┐     │ │
+ *      │ EVENT_VM_BIND_OP #n   ├─────┘ │
+ *      └───────────────────────┘       │
+ *                                      │
+ *      ┌───────────────────────┐       │
+ *      │ EVENT_UFENCE          ├───────┘
+ *      └───────────────────────┘
+ *
+ * All the events below VM_BIND will reference the VM_BIND
+ * they associate with, by field .vm_bind_ref_seqno.
+ * event_ufence will only be included if the client did
+ * attach sync of type UFENCE into its vm_bind_ioctl().
+ *
+ * When EVENT_UFENCE is sent by the driver, all the OPs of
+ * the original VM_BIND are completed and the [addr,range]
+ * contained in them are present and modifiable through the
+ * vm accessors. Accessing [addr, range] before related ufence
+ * event will lead to undefined results as the actual bind
+ * operations are async and the backing storage might not
+ * be there on a moment of receiving the event.
+ *
+ * Client's UFENCE sync will be held by the driver: client's
+ * drm_xe_wait_ufence will not complete and the value of the ufence
+ * won't appear until ufence is acked by the debugger process calling
+ * DRM_XE_EUDEBUG_IOCTL_ACK_EVENT with the event_ufence.base.seqno.
+ * This will signal the fence, .value will update and the wait will
+ * complete allowing the client to continue.
+ *
+ */
+
+struct prelim_drm_xe_eudebug_event_vm_bind {
+	struct prelim_drm_xe_eudebug_event base;
+
+	__u64 client_handle;
+	__u64 vm_handle;
+
+	__u32 flags;
+#define PRELIM_DRM_XE_EUDEBUG_EVENT_VM_BIND_FLAG_UFENCE (1 << 0)
+
+	__u32 num_binds;
+};
+
+struct prelim_drm_xe_eudebug_event_vm_bind_op {
+	struct prelim_drm_xe_eudebug_event base;
+	__u64 vm_bind_ref_seqno; /* *_event_vm_bind.base.seqno */
+	__u64 num_extensions;
+
+	__u64 addr; /* XXX: Zero for unmap all? */
+	__u64 range; /* XXX: Zero for unmap all? */
+};
+
+struct prelim_drm_xe_eudebug_event_vm_bind_ufence {
+	struct prelim_drm_xe_eudebug_event base;
+	__u64 vm_bind_ref_seqno; /* *_event_vm_bind.base.seqno */
+};
+
+struct prelim_drm_xe_eudebug_ack_event {
+	__u32 type;
+	__u32 flags; /* MBZ */
+	__u64 seqno;
+};
+
+struct prelim_drm_xe_eudebug_vm_open {
+	/** @extensions: Pointer to the first extension struct, if any */
+	__u64 extensions;
+
+	/** @client_handle: id of client */
+	__u64 client_handle;
+
+	/** @vm_handle: id of vm */
+	__u64 vm_handle;
+
+	/** @flags: flags */
+	__u64 flags;
+
+#define PRELIM_DRM_XE_EUDEBUG_VM_SYNC_MAX_TIMEOUT_NSECS (10ULL * NSEC_PER_SEC)
+	/** @timeout_ns: Timeout value in nanoseconds operations (fsync) */
+	__u64 timeout_ns;
+};
+
+struct prelim_drm_xe_eudebug_read_metadata {
+	__u64 client_handle;
+	__u64 metadata_handle;
+	__u32 flags;
+	__u32 reserved;
+	__u64 ptr;
+	__u64 size;
+};
+
+struct prelim_drm_xe_eudebug_event_metadata {
+	struct prelim_drm_xe_eudebug_event base;
+
+	__u64 client_handle;
+	__u64 metadata_handle;
+	/* XXX: Refer to xe_drm.h for fields */
+	__u64 type;
+	__u64 len;
+};
+
+struct prelim_drm_xe_eudebug_event_vm_bind_op_metadata {
+	struct prelim_drm_xe_eudebug_event base;
+	__u64 vm_bind_op_ref_seqno; /* *_event_vm_bind_op.base.seqno */
+
+	__u64 metadata_handle;
+	__u64 metadata_cookie;
+};
+
+struct prelim_drm_xe_eudebug_event_pagefault {
+	struct prelim_drm_xe_eudebug_event base;
+
+	__u64 client_handle;
+	__u64 exec_queue_handle;
+	__u64 lrc_handle;
+	__u32 flags;
+	__u32 bitmask_size;
+	__u64 pagefault_address;
+	__u8 bitmask[];
+};
+
 #endif /* _UAPI_XE_DRM_PRELIM_H_ */
-- 
2.34.1

